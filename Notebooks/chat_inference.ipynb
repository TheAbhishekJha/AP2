{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /home/ajha/motives/venv/lib/python3.8/site-packages (24.0)\n",
      "Collecting pip\n",
      "  Downloading pip-25.0.1-py3-none-any.whl.metadata (3.7 kB)\n",
      "Downloading pip-25.0.1-py3-none-any.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m27.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pip\n",
      "  Attempting uninstall: pip\n",
      "    Found existing installation: pip 24.0\n",
      "    Uninstalling pip-24.0:\n",
      "      Successfully uninstalled pip-24.0\n",
      "Successfully installed pip-25.0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data and drop individual #2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ajha/motives/venv/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/ajha/motives/venv/lib/python3.8/site-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "import os\n",
    "\n",
    "# Load the WASSA 2023 dataset\n",
    "wassa_file_path = \"/home/ajha/AP2/data/WASSA23_conv_level_with_labels_train.tsv\"\n",
    "wassa_df = pd.read_csv(wassa_file_path, sep=\"\\t\")\n",
    "\n",
    "# Load the articles dataset\n",
    "articles_file_path = \"/home/ajha/AP2/data/articles_adobe_AMT.csv\"\n",
    "articles_df = pd.read_csv(articles_file_path)\n",
    "\n",
    "# Separate out the turns spoken by the first individual (speaker_number == 1) in each conversation\n",
    "first_individual_turns = wassa_df[wassa_df[\"speaker_number\"] == 1]\n",
    "\n",
    "# Sort the first individual's turns within each conversation by turn_id in ascending order\n",
    "first_individual_turns_sorted = first_individual_turns.sort_values(by=[\"conversation_id\", \"turn_id\"])\n",
    "\n",
    "# Rename the text column in the articles dataset for clarity\n",
    "articles_df.rename(columns={\"text\": \"article\"}, inplace=True)\n",
    "\n",
    "# Merge the first individual's turns dataset with the articles dataset using article_id\n",
    "first_individual_turns_sorted = first_individual_turns_sorted.merge(articles_df, on=\"article_id\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conversation_id</th>\n",
       "      <th>turn_id</th>\n",
       "      <th>text</th>\n",
       "      <th>EmotionalPolarity</th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Empathy</th>\n",
       "      <th>speaker_number</th>\n",
       "      <th>article_id</th>\n",
       "      <th>speaker_id</th>\n",
       "      <th>essay_id</th>\n",
       "      <th>article</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>I feel very sad for the people.</td>\n",
       "      <td>2.0000</td>\n",
       "      <td>3.0000</td>\n",
       "      <td>3.3333</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>A month after Hurricane Matthew, 800,000 Haiti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Yeah, the whole situation is horrible.</td>\n",
       "      <td>2.0000</td>\n",
       "      <td>3.6667</td>\n",
       "      <td>3.6667</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>A month after Hurricane Matthew, 800,000 Haiti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>I know we can donate, but it's hard to know ex...</td>\n",
       "      <td>1.6667</td>\n",
       "      <td>3.0000</td>\n",
       "      <td>2.3333</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>A month after Hurricane Matthew, 800,000 Haiti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>No, and You?</td>\n",
       "      <td>1.3333</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>A month after Hurricane Matthew, 800,000 Haiti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>Sorry to hear that, I'm glad that you are okay!</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>3.0000</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>A month after Hurricane Matthew, 800,000 Haiti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>I felt really sorry for the sister that now ha...</td>\n",
       "      <td>2.0000</td>\n",
       "      <td>3.6667</td>\n",
       "      <td>2.6667</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>A month after Hurricane Matthew, 800,000 Haiti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>Yeah, we never know what we can do unless we a...</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>2.3333</td>\n",
       "      <td>1.3333</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>A month after Hurricane Matthew, 800,000 Haiti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>Tornado when I was young. They suck too.</td>\n",
       "      <td>2.0000</td>\n",
       "      <td>2.0000</td>\n",
       "      <td>1.6667</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>A month after Hurricane Matthew, 800,000 Haiti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>The power of nature is truly scary.</td>\n",
       "      <td>1.6667</td>\n",
       "      <td>3.3333</td>\n",
       "      <td>1.3333</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>A month after Hurricane Matthew, 800,000 Haiti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>Me too, I wish there was a direct way to aid t...</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>2.6667</td>\n",
       "      <td>3.6667</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>A month after Hurricane Matthew, 800,000 Haiti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>You too! bye</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>2.0000</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>A month after Hurricane Matthew, 800,000 Haiti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>what did you think about the article</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.6667</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>A month after Hurricane Matthew, 800,000 Haiti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>its crazy the stuff that goes on in this world</td>\n",
       "      <td>1.3333</td>\n",
       "      <td>4.0000</td>\n",
       "      <td>3.3333</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>A month after Hurricane Matthew, 800,000 Haiti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>yeah some countries are so corrupt though</td>\n",
       "      <td>2.0000</td>\n",
       "      <td>3.3333</td>\n",
       "      <td>3.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>A month after Hurricane Matthew, 800,000 Haiti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>i remember  trump throwing toilet paper rolls ...</td>\n",
       "      <td>2.0000</td>\n",
       "      <td>3.3333</td>\n",
       "      <td>2.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>A month after Hurricane Matthew, 800,000 Haiti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>yeah wonder what was going through is head</td>\n",
       "      <td>1.3333</td>\n",
       "      <td>2.3333</td>\n",
       "      <td>2.3333</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>A month after Hurricane Matthew, 800,000 Haiti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>what do you think can be done to help the peop...</td>\n",
       "      <td>0.6667</td>\n",
       "      <td>2.3333</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>A month after Hurricane Matthew, 800,000 Haiti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>makes sense. also find better ways rather than...</td>\n",
       "      <td>0.6667</td>\n",
       "      <td>2.6667</td>\n",
       "      <td>3.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>A month after Hurricane Matthew, 800,000 Haiti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>and also not let the haitian govt get there ha...</td>\n",
       "      <td>1.3333</td>\n",
       "      <td>2.6667</td>\n",
       "      <td>2.6667</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>A month after Hurricane Matthew, 800,000 Haiti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>thats a great idea</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>2.3333</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>A month after Hurricane Matthew, 800,000 Haiti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>me too very interested in the outcome</td>\n",
       "      <td>0.6667</td>\n",
       "      <td>2.3333</td>\n",
       "      <td>2.3333</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>A month after Hurricane Matthew, 800,000 Haiti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>were lucky to live here</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>2.3333</td>\n",
       "      <td>1.6667</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>A month after Hurricane Matthew, 800,000 Haiti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>3</td>\n",
       "      <td>22</td>\n",
       "      <td>yeah makes u realize your problems are miniscu...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>3.0000</td>\n",
       "      <td>2.6667</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>A month after Hurricane Matthew, 800,000 Haiti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>3</td>\n",
       "      <td>24</td>\n",
       "      <td>bye</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>A month after Hurricane Matthew, 800,000 Haiti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>Please, what did you think about the article</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>A month after Hurricane Matthew, 800,000 Haiti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>It's terrible. I feel bad for all the people l...</td>\n",
       "      <td>2.0000</td>\n",
       "      <td>4.0000</td>\n",
       "      <td>4.3333</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>A month after Hurricane Matthew, 800,000 Haiti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>Agree. Have you ever been in a hurricane?</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.6667</td>\n",
       "      <td>1.3333</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>A month after Hurricane Matthew, 800,000 Haiti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>Wow, Haiti sounds awesome. I'm from Florida so...</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>3.0000</td>\n",
       "      <td>2.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>A month after Hurricane Matthew, 800,000 Haiti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>It's pretty stressful when hurricanes hit. I o...</td>\n",
       "      <td>2.0000</td>\n",
       "      <td>3.0000</td>\n",
       "      <td>1.6667</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>A month after Hurricane Matthew, 800,000 Haiti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>It's scary because all you can do is hide in y...</td>\n",
       "      <td>2.0000</td>\n",
       "      <td>3.6667</td>\n",
       "      <td>3.3333</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>A month after Hurricane Matthew, 800,000 Haiti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>Yeah it's definitely very different. The air p...</td>\n",
       "      <td>1.6667</td>\n",
       "      <td>2.3333</td>\n",
       "      <td>2.3333</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>A month after Hurricane Matthew, 800,000 Haiti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "      <td>Atlantic, i've lived in Florida for about 8 ye...</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>2.0000</td>\n",
       "      <td>0.6667</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>A month after Hurricane Matthew, 800,000 Haiti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "      <td>I didn't think of that. That's why i don't eve...</td>\n",
       "      <td>1.6667</td>\n",
       "      <td>2.3333</td>\n",
       "      <td>3.3333</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>A month after Hurricane Matthew, 800,000 Haiti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>5</td>\n",
       "      <td>18</td>\n",
       "      <td>Sad that people are so corrupt. I really hope ...</td>\n",
       "      <td>2.0000</td>\n",
       "      <td>2.6667</td>\n",
       "      <td>2.3333</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>A month after Hurricane Matthew, 800,000 Haiti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>what a sad thing to happen to someone who has ...</td>\n",
       "      <td>2.0000</td>\n",
       "      <td>3.3333</td>\n",
       "      <td>3.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>213.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Miami Marlins star pitcher Jose Fernandez kill...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>what a freak accident</td>\n",
       "      <td>1.6667</td>\n",
       "      <td>2.6667</td>\n",
       "      <td>2.3333</td>\n",
       "      <td>1</td>\n",
       "      <td>213.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Miami Marlins star pitcher Jose Fernandez kill...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>he had the true american dream story</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>3.0000</td>\n",
       "      <td>2.3333</td>\n",
       "      <td>1</td>\n",
       "      <td>213.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Miami Marlins star pitcher Jose Fernandez kill...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>yup but going from poor to crazy rich all from...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>3.0000</td>\n",
       "      <td>2.3333</td>\n",
       "      <td>1</td>\n",
       "      <td>213.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Miami Marlins star pitcher Jose Fernandez kill...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>I wonder if the team retired his number to hon...</td>\n",
       "      <td>0.6667</td>\n",
       "      <td>2.0000</td>\n",
       "      <td>2.3333</td>\n",
       "      <td>1</td>\n",
       "      <td>213.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Miami Marlins star pitcher Jose Fernandez kill...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>yes, I watch the yankees almost every night. H...</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.3333</td>\n",
       "      <td>0.6667</td>\n",
       "      <td>1</td>\n",
       "      <td>213.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Miami Marlins star pitcher Jose Fernandez kill...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>yes! they made it to the playoffs!</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>3.0000</td>\n",
       "      <td>0.6667</td>\n",
       "      <td>1</td>\n",
       "      <td>213.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Miami Marlins star pitcher Jose Fernandez kill...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "      <td>I heard about it in the news when it happened ...</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.6667</td>\n",
       "      <td>2.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>213.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Miami Marlins star pitcher Jose Fernandez kill...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "      <td>I remember hearing he jumped into the water he...</td>\n",
       "      <td>1.3333</td>\n",
       "      <td>2.0000</td>\n",
       "      <td>2.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>213.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Miami Marlins star pitcher Jose Fernandez kill...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>6</td>\n",
       "      <td>18</td>\n",
       "      <td>i couldn't imagine being the family of him tha...</td>\n",
       "      <td>2.0000</td>\n",
       "      <td>3.6667</td>\n",
       "      <td>3.6667</td>\n",
       "      <td>1</td>\n",
       "      <td>213.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Miami Marlins star pitcher Jose Fernandez kill...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>6</td>\n",
       "      <td>20</td>\n",
       "      <td>bye</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.6667</td>\n",
       "      <td>1</td>\n",
       "      <td>213.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Miami Marlins star pitcher Jose Fernandez kill...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>Sounded like a very kindhearted man.</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>3.0000</td>\n",
       "      <td>3.3333</td>\n",
       "      <td>1</td>\n",
       "      <td>213.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Miami Marlins star pitcher Jose Fernandez kill...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>I was wondering if no drugs or alcohol were in...</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.3333</td>\n",
       "      <td>2.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>213.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Miami Marlins star pitcher Jose Fernandez kill...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>That could have been it.</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.3333</td>\n",
       "      <td>2.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>213.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Miami Marlins star pitcher Jose Fernandez kill...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>It was nice that he saved his mom not knowing ...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>2.6667</td>\n",
       "      <td>3.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>213.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Miami Marlins star pitcher Jose Fernandez kill...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>Yeah, It was nice for the team to get the visa.</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>2.6667</td>\n",
       "      <td>3.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>213.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Miami Marlins star pitcher Jose Fernandez kill...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    conversation_id  turn_id  \\\n",
       "0                 2        0   \n",
       "1                 2        2   \n",
       "2                 2        4   \n",
       "3                 2        6   \n",
       "4                 2        8   \n",
       "5                 2       10   \n",
       "6                 2       12   \n",
       "7                 2       14   \n",
       "8                 2       16   \n",
       "9                 2       18   \n",
       "10                2       20   \n",
       "11                3        0   \n",
       "12                3        2   \n",
       "13                3        4   \n",
       "14                3        6   \n",
       "15                3        8   \n",
       "16                3       10   \n",
       "17                3       12   \n",
       "18                3       14   \n",
       "19                3       16   \n",
       "20                3       18   \n",
       "21                3       20   \n",
       "22                3       22   \n",
       "23                3       24   \n",
       "24                5        0   \n",
       "25                5        2   \n",
       "26                5        4   \n",
       "27                5        6   \n",
       "28                5        8   \n",
       "29                5       10   \n",
       "30                5       12   \n",
       "31                5       14   \n",
       "32                5       16   \n",
       "33                5       18   \n",
       "34                6        0   \n",
       "35                6        2   \n",
       "36                6        4   \n",
       "37                6        6   \n",
       "38                6        8   \n",
       "39                6       10   \n",
       "40                6       12   \n",
       "41                6       14   \n",
       "42                6       16   \n",
       "43                6       18   \n",
       "44                6       20   \n",
       "45                8        0   \n",
       "46                8        2   \n",
       "47                8        4   \n",
       "48                8        6   \n",
       "49                8        8   \n",
       "\n",
       "                                                 text  EmotionalPolarity  \\\n",
       "0                     I feel very sad for the people.             2.0000   \n",
       "1              Yeah, the whole situation is horrible.             2.0000   \n",
       "2   I know we can donate, but it's hard to know ex...             1.6667   \n",
       "3                                        No, and You?             1.3333   \n",
       "4     Sorry to hear that, I'm glad that you are okay!             0.3333   \n",
       "5   I felt really sorry for the sister that now ha...             2.0000   \n",
       "6   Yeah, we never know what we can do unless we a...             0.3333   \n",
       "7            Tornado when I was young. They suck too.             2.0000   \n",
       "8                 The power of nature is truly scary.             1.6667   \n",
       "9   Me too, I wish there was a direct way to aid t...             1.0000   \n",
       "10                                       You too! bye             0.3333   \n",
       "11               what did you think about the article             1.0000   \n",
       "12     its crazy the stuff that goes on in this world             1.3333   \n",
       "13          yeah some countries are so corrupt though             2.0000   \n",
       "14  i remember  trump throwing toilet paper rolls ...             2.0000   \n",
       "15         yeah wonder what was going through is head             1.3333   \n",
       "16  what do you think can be done to help the peop...             0.6667   \n",
       "17  makes sense. also find better ways rather than...             0.6667   \n",
       "18  and also not let the haitian govt get there ha...             1.3333   \n",
       "19                                 thats a great idea             0.3333   \n",
       "20              me too very interested in the outcome             0.6667   \n",
       "21                            were lucky to live here             0.0000   \n",
       "22  yeah makes u realize your problems are miniscu...             0.0000   \n",
       "23                                                bye             1.0000   \n",
       "24       Please, what did you think about the article             1.0000   \n",
       "25  It's terrible. I feel bad for all the people l...             2.0000   \n",
       "26          Agree. Have you ever been in a hurricane?             1.0000   \n",
       "27  Wow, Haiti sounds awesome. I'm from Florida so...             0.3333   \n",
       "28  It's pretty stressful when hurricanes hit. I o...             2.0000   \n",
       "29  It's scary because all you can do is hide in y...             2.0000   \n",
       "30  Yeah it's definitely very different. The air p...             1.6667   \n",
       "31  Atlantic, i've lived in Florida for about 8 ye...             1.0000   \n",
       "32  I didn't think of that. That's why i don't eve...             1.6667   \n",
       "33  Sad that people are so corrupt. I really hope ...             2.0000   \n",
       "34  what a sad thing to happen to someone who has ...             2.0000   \n",
       "35                              what a freak accident             1.6667   \n",
       "36               he had the true american dream story             0.3333   \n",
       "37  yup but going from poor to crazy rich all from...             0.0000   \n",
       "38  I wonder if the team retired his number to hon...             0.6667   \n",
       "39  yes, I watch the yankees almost every night. H...             1.0000   \n",
       "40                 yes! they made it to the playoffs!             0.0000   \n",
       "41  I heard about it in the news when it happened ...             1.0000   \n",
       "42  I remember hearing he jumped into the water he...             1.3333   \n",
       "43  i couldn't imagine being the family of him tha...             2.0000   \n",
       "44                                                bye             1.0000   \n",
       "45               Sounded like a very kindhearted man.             0.0000   \n",
       "46  I was wondering if no drugs or alcohol were in...             1.0000   \n",
       "47                           That could have been it.             1.0000   \n",
       "48  It was nice that he saved his mom not knowing ...             0.0000   \n",
       "49    Yeah, It was nice for the team to get the visa.             0.0000   \n",
       "\n",
       "    Emotion  Empathy  speaker_number  article_id  speaker_id  essay_id  \\\n",
       "0    3.0000   3.3333               1        35.0        30.0       1.0   \n",
       "1    3.6667   3.6667               1        35.0        30.0       1.0   \n",
       "2    3.0000   2.3333               1        35.0        30.0       1.0   \n",
       "3    1.0000   0.3333               1        35.0        30.0       1.0   \n",
       "4    3.0000   0.3333               1        35.0        30.0       1.0   \n",
       "5    3.6667   2.6667               1        35.0        30.0       1.0   \n",
       "6    2.3333   1.3333               1        35.0        30.0       1.0   \n",
       "7    2.0000   1.6667               1        35.0        30.0       1.0   \n",
       "8    3.3333   1.3333               1        35.0        30.0       1.0   \n",
       "9    2.6667   3.6667               1        35.0        30.0       1.0   \n",
       "10   2.0000   0.3333               1        35.0        30.0       1.0   \n",
       "11   0.6667   0.3333               1        35.0        19.0       2.0   \n",
       "12   4.0000   3.3333               1        35.0        19.0       2.0   \n",
       "13   3.3333   3.0000               1        35.0        19.0       2.0   \n",
       "14   3.3333   2.0000               1        35.0        19.0       2.0   \n",
       "15   2.3333   2.3333               1        35.0        19.0       2.0   \n",
       "16   2.3333   1.0000               1        35.0        19.0       2.0   \n",
       "17   2.6667   3.0000               1        35.0        19.0       2.0   \n",
       "18   2.6667   2.6667               1        35.0        19.0       2.0   \n",
       "19   2.3333   1.0000               1        35.0        19.0       2.0   \n",
       "20   2.3333   2.3333               1        35.0        19.0       2.0   \n",
       "21   2.3333   1.6667               1        35.0        19.0       2.0   \n",
       "22   3.0000   2.6667               1        35.0        19.0       2.0   \n",
       "23   1.0000   0.3333               1        35.0        19.0       2.0   \n",
       "24   1.0000   1.0000               1        35.0        17.0       4.0   \n",
       "25   4.0000   4.3333               1        35.0        17.0       4.0   \n",
       "26   1.6667   1.3333               1        35.0        17.0       4.0   \n",
       "27   3.0000   2.0000               1        35.0        17.0       4.0   \n",
       "28   3.0000   1.6667               1        35.0        17.0       4.0   \n",
       "29   3.6667   3.3333               1        35.0        17.0       4.0   \n",
       "30   2.3333   2.3333               1        35.0        17.0       4.0   \n",
       "31   2.0000   0.6667               1        35.0        17.0       4.0   \n",
       "32   2.3333   3.3333               1        35.0        17.0       4.0   \n",
       "33   2.6667   2.3333               1        35.0        17.0       4.0   \n",
       "34   3.3333   3.0000               1       213.0        16.0       5.0   \n",
       "35   2.6667   2.3333               1       213.0        16.0       5.0   \n",
       "36   3.0000   2.3333               1       213.0        16.0       5.0   \n",
       "37   3.0000   2.3333               1       213.0        16.0       5.0   \n",
       "38   2.0000   2.3333               1       213.0        16.0       5.0   \n",
       "39   1.3333   0.6667               1       213.0        16.0       5.0   \n",
       "40   3.0000   0.6667               1       213.0        16.0       5.0   \n",
       "41   1.6667   2.0000               1       213.0        16.0       5.0   \n",
       "42   2.0000   2.0000               1       213.0        16.0       5.0   \n",
       "43   3.6667   3.6667               1       213.0        16.0       5.0   \n",
       "44   1.0000   0.6667               1       213.0        16.0       5.0   \n",
       "45   3.0000   3.3333               1       213.0        30.0       7.0   \n",
       "46   1.3333   2.0000               1       213.0        30.0       7.0   \n",
       "47   1.3333   2.0000               1       213.0        30.0       7.0   \n",
       "48   2.6667   3.0000               1       213.0        30.0       7.0   \n",
       "49   2.6667   3.0000               1       213.0        30.0       7.0   \n",
       "\n",
       "                                              article  \n",
       "0   A month after Hurricane Matthew, 800,000 Haiti...  \n",
       "1   A month after Hurricane Matthew, 800,000 Haiti...  \n",
       "2   A month after Hurricane Matthew, 800,000 Haiti...  \n",
       "3   A month after Hurricane Matthew, 800,000 Haiti...  \n",
       "4   A month after Hurricane Matthew, 800,000 Haiti...  \n",
       "5   A month after Hurricane Matthew, 800,000 Haiti...  \n",
       "6   A month after Hurricane Matthew, 800,000 Haiti...  \n",
       "7   A month after Hurricane Matthew, 800,000 Haiti...  \n",
       "8   A month after Hurricane Matthew, 800,000 Haiti...  \n",
       "9   A month after Hurricane Matthew, 800,000 Haiti...  \n",
       "10  A month after Hurricane Matthew, 800,000 Haiti...  \n",
       "11  A month after Hurricane Matthew, 800,000 Haiti...  \n",
       "12  A month after Hurricane Matthew, 800,000 Haiti...  \n",
       "13  A month after Hurricane Matthew, 800,000 Haiti...  \n",
       "14  A month after Hurricane Matthew, 800,000 Haiti...  \n",
       "15  A month after Hurricane Matthew, 800,000 Haiti...  \n",
       "16  A month after Hurricane Matthew, 800,000 Haiti...  \n",
       "17  A month after Hurricane Matthew, 800,000 Haiti...  \n",
       "18  A month after Hurricane Matthew, 800,000 Haiti...  \n",
       "19  A month after Hurricane Matthew, 800,000 Haiti...  \n",
       "20  A month after Hurricane Matthew, 800,000 Haiti...  \n",
       "21  A month after Hurricane Matthew, 800,000 Haiti...  \n",
       "22  A month after Hurricane Matthew, 800,000 Haiti...  \n",
       "23  A month after Hurricane Matthew, 800,000 Haiti...  \n",
       "24  A month after Hurricane Matthew, 800,000 Haiti...  \n",
       "25  A month after Hurricane Matthew, 800,000 Haiti...  \n",
       "26  A month after Hurricane Matthew, 800,000 Haiti...  \n",
       "27  A month after Hurricane Matthew, 800,000 Haiti...  \n",
       "28  A month after Hurricane Matthew, 800,000 Haiti...  \n",
       "29  A month after Hurricane Matthew, 800,000 Haiti...  \n",
       "30  A month after Hurricane Matthew, 800,000 Haiti...  \n",
       "31  A month after Hurricane Matthew, 800,000 Haiti...  \n",
       "32  A month after Hurricane Matthew, 800,000 Haiti...  \n",
       "33  A month after Hurricane Matthew, 800,000 Haiti...  \n",
       "34  Miami Marlins star pitcher Jose Fernandez kill...  \n",
       "35  Miami Marlins star pitcher Jose Fernandez kill...  \n",
       "36  Miami Marlins star pitcher Jose Fernandez kill...  \n",
       "37  Miami Marlins star pitcher Jose Fernandez kill...  \n",
       "38  Miami Marlins star pitcher Jose Fernandez kill...  \n",
       "39  Miami Marlins star pitcher Jose Fernandez kill...  \n",
       "40  Miami Marlins star pitcher Jose Fernandez kill...  \n",
       "41  Miami Marlins star pitcher Jose Fernandez kill...  \n",
       "42  Miami Marlins star pitcher Jose Fernandez kill...  \n",
       "43  Miami Marlins star pitcher Jose Fernandez kill...  \n",
       "44  Miami Marlins star pitcher Jose Fernandez kill...  \n",
       "45  Miami Marlins star pitcher Jose Fernandez kill...  \n",
       "46  Miami Marlins star pitcher Jose Fernandez kill...  \n",
       "47  Miami Marlins star pitcher Jose Fernandez kill...  \n",
       "48  Miami Marlins star pitcher Jose Fernandez kill...  \n",
       "49  Miami Marlins star pitcher Jose Fernandez kill...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_individual_turns_sorted[:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the model for inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:07<00:00,  1.76s/it]\n"
     ]
    }
   ],
   "source": [
    "# Load LLaMA 3.1 8B model and tokenizer\n",
    "model_name = \"/chronos_data/pretrained_models/llama3.1-8b-Instruct-hf/\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, torch_dtype=torch.float16, device_map=\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_model(article, conversation_history, latest_dialogue):\n",
    "    prompt = f\"\"\"\n",
    "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
    "You are participating in a two-person conversation about the provided article.  \n",
    "Respond only to your human partner's latest dialogue as if you are having a conversation. \n",
    "Keep your response natural and concise.\n",
    "\n",
    "Article:\n",
    "{article}\n",
    "\n",
    "Conversation so far:\n",
    "{conversation_history if conversation_history else 'START'}\n",
    "\n",
    "<|start_header_id|>partner<|end_header_id|>\n",
    "{latest_dialogue}\n",
    "\n",
    "<|start_header_id|>you<|end_header_id|>\n",
    "\"\"\"\n",
    "\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "    with torch.no_grad():\n",
    "        output = model.generate(**inputs, max_new_tokens=100, temperature=0.8, pad_token_id=tokenizer.eos_token_id)\n",
    "    \n",
    "    return tokenizer.decode(output[0][inputs.input_ids.shape[-1]:], skip_special_tokens=True).strip()\n",
    "\n",
    "\n",
    "def query_model(article, conversation_history, latest_dialogue):\n",
    "    prompt = f\"\"\"\n",
    "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
    "You are a thoughtful and emotionally intelligent individual participating in a conversation about the article below.\n",
    "Respond to your partner in a way that reflects your unique personality, opinions, and emotional reactions.\n",
    "Try to show your values, empathy, and worldview through what you say.\n",
    "Keep your response concise—roughly matching your partner’s message length.\n",
    "\n",
    "Article:\n",
    "{article}\n",
    "\n",
    "Conversation so far:\n",
    "{conversation_history if conversation_history else 'START'}\n",
    "\n",
    "<|start_header_id|>partner<|end_header_id|>\n",
    "{latest_dialogue}\n",
    "\n",
    "<|start_header_id|>you<|end_header_id|>\n",
    "\"\"\"\n",
    "\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "    with torch.no_grad():\n",
    "        output = model.generate(**inputs, max_new_tokens=100, temperature=0.8, pad_token_id=tokenizer.eos_token_id)\n",
    "    \n",
    "    return tokenizer.decode(output[0][inputs.input_ids.shape[-1]:], skip_special_tokens=True).strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running conversation ID: 492\n",
      "\n",
      "Individual 1: This article is so concerning.\n",
      " awaiting response\n",
      "Model: I know, it's terrifying. The fact that 18 million people are exposed to lead in their drinking water is just unacceptable. And to think that so few water suppliers are being held accountable for these violations is even more disturbing. It's like, what's the point of having regulations if they're not being enforced?\n",
      "\n",
      "Individual 1: Why do all the work to see if drinking water is safe, and then assess no fines or penalties?\n",
      " awaiting response\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 14\u001b[0m\n\u001b[1;32m     12\u001b[0m latest_dialogue \u001b[38;5;241m=\u001b[39m row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIndividual 1: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlatest_dialogue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m awaiting response\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 14\u001b[0m model_response \u001b[38;5;241m=\u001b[39m \u001b[43mquery_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43marticle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconversation_history\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlatest_dialogue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_response\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Update conversation history\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[6], line 49\u001b[0m, in \u001b[0;36mquery_model\u001b[0;34m(article, conversation_history, latest_dialogue)\u001b[0m\n\u001b[1;32m     47\u001b[0m inputs \u001b[38;5;241m=\u001b[39m tokenizer(prompt, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 49\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.8\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpad_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meos_token_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tokenizer\u001b[38;5;241m.\u001b[39mdecode(output[\u001b[38;5;241m0\u001b[39m][inputs\u001b[38;5;241m.\u001b[39minput_ids\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]:], skip_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\u001b[38;5;241m.\u001b[39mstrip()\n",
      "File \u001b[0;32m~/motives/venv/lib/python3.8/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/motives/venv/lib/python3.8/site-packages/transformers/generation/utils.py:2215\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   2207\u001b[0m     input_ids, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_inputs_for_generation(\n\u001b[1;32m   2208\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m   2209\u001b[0m         expand_size\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_return_sequences,\n\u001b[1;32m   2210\u001b[0m         is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[1;32m   2211\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[1;32m   2212\u001b[0m     )\n\u001b[1;32m   2214\u001b[0m     \u001b[38;5;66;03m# 12. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001b[39;00m\n\u001b[0;32m-> 2215\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2216\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2217\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2218\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2219\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2220\u001b[0m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2221\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstreamer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstreamer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2222\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2223\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2225\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;129;01min\u001b[39;00m (GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SAMPLE, GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SEARCH):\n\u001b[1;32m   2226\u001b[0m     \u001b[38;5;66;03m# 11. prepare beam search scorer\u001b[39;00m\n\u001b[1;32m   2227\u001b[0m     beam_scorer \u001b[38;5;241m=\u001b[39m BeamSearchScorer(\n\u001b[1;32m   2228\u001b[0m         batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m   2229\u001b[0m         num_beams\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_beams,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2234\u001b[0m         max_length\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mmax_length,\n\u001b[1;32m   2235\u001b[0m     )\n",
      "File \u001b[0;32m~/motives/venv/lib/python3.8/site-packages/transformers/generation/utils.py:3206\u001b[0m, in \u001b[0;36mGenerationMixin._sample\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[1;32m   3203\u001b[0m model_inputs\u001b[38;5;241m.\u001b[39mupdate({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_hidden_states\u001b[39m\u001b[38;5;124m\"\u001b[39m: output_hidden_states} \u001b[38;5;28;01mif\u001b[39;00m output_hidden_states \u001b[38;5;28;01melse\u001b[39;00m {})\n\u001b[1;32m   3205\u001b[0m \u001b[38;5;66;03m# forward pass to get next token\u001b[39;00m\n\u001b[0;32m-> 3206\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   3208\u001b[0m \u001b[38;5;66;03m# synced_gpus: don't waste resources running the code we don't need; kwargs must be updated before skipping\u001b[39;00m\n\u001b[1;32m   3209\u001b[0m model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_model_kwargs_for_generation(\n\u001b[1;32m   3210\u001b[0m     outputs,\n\u001b[1;32m   3211\u001b[0m     model_kwargs,\n\u001b[1;32m   3212\u001b[0m     is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[1;32m   3213\u001b[0m )\n",
      "File \u001b[0;32m~/motives/venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/motives/venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/motives/venv/lib/python3.8/site-packages/transformers/models/llama/modeling_llama.py:1190\u001b[0m, in \u001b[0;36mLlamaForCausalLM.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, cache_position, num_logits_to_keep, **loss_kwargs)\u001b[0m\n\u001b[1;32m   1187\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m   1189\u001b[0m \u001b[38;5;66;03m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[0;32m-> 1190\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1191\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1192\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1193\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1194\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1196\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1197\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1198\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1199\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1200\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1201\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1203\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1204\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mpretraining_tp \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/motives/venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/motives/venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/motives/venv/lib/python3.8/site-packages/transformers/models/llama/modeling_llama.py:945\u001b[0m, in \u001b[0;36mLlamaModel.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[1;32m    933\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m    934\u001b[0m         decoder_layer\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m    935\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    942\u001b[0m         position_embeddings,\n\u001b[1;32m    943\u001b[0m     )\n\u001b[1;32m    944\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 945\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    946\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    947\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcausal_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    948\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    949\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    950\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    951\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    952\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    953\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    954\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    956\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    958\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m~/motives/venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/motives/venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/motives/venv/lib/python3.8/site-packages/transformers/models/llama/modeling_llama.py:676\u001b[0m, in \u001b[0;36mLlamaDecoderLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, cache_position, position_embeddings, **kwargs)\u001b[0m\n\u001b[1;32m    673\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_layernorm(hidden_states)\n\u001b[1;32m    675\u001b[0m \u001b[38;5;66;03m# Self Attention\u001b[39;00m\n\u001b[0;32m--> 676\u001b[0m hidden_states, self_attn_weights, present_key_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself_attn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    677\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    678\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    679\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    680\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    681\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    682\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    683\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    684\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    685\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    686\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    687\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m residual \u001b[38;5;241m+\u001b[39m hidden_states\n\u001b[1;32m    689\u001b[0m \u001b[38;5;66;03m# Fully Connected\u001b[39;00m\n",
      "File \u001b[0;32m~/motives/venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/motives/venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/motives/venv/lib/python3.8/site-packages/transformers/models/llama/modeling_llama.py:577\u001b[0m, in \u001b[0;36mLlamaSdpaAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, cache_position, position_embeddings, **kwargs)\u001b[0m\n\u001b[1;32m    575\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    576\u001b[0m     cos, sin \u001b[38;5;241m=\u001b[39m position_embeddings\n\u001b[0;32m--> 577\u001b[0m query_states, key_states \u001b[38;5;241m=\u001b[39m \u001b[43mapply_rotary_pos_emb\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery_states\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey_states\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msin\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    579\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m past_key_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    580\u001b[0m     \u001b[38;5;66;03m# sin and cos are specific to RoPE models; cache_position needed for the static cache\u001b[39;00m\n\u001b[1;32m    581\u001b[0m     cache_kwargs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msin\u001b[39m\u001b[38;5;124m\"\u001b[39m: sin, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcos\u001b[39m\u001b[38;5;124m\"\u001b[39m: cos, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcache_position\u001b[39m\u001b[38;5;124m\"\u001b[39m: cache_position}\n",
      "File \u001b[0;32m~/motives/venv/lib/python3.8/site-packages/transformers/models/llama/modeling_llama.py:225\u001b[0m, in \u001b[0;36mapply_rotary_pos_emb\u001b[0;34m(q, k, cos, sin, position_ids, unsqueeze_dim)\u001b[0m\n\u001b[1;32m    223\u001b[0m sin \u001b[38;5;241m=\u001b[39m sin\u001b[38;5;241m.\u001b[39munsqueeze(unsqueeze_dim)\n\u001b[1;32m    224\u001b[0m q_embed \u001b[38;5;241m=\u001b[39m (q \u001b[38;5;241m*\u001b[39m cos) \u001b[38;5;241m+\u001b[39m (rotate_half(q) \u001b[38;5;241m*\u001b[39m sin)\n\u001b[0;32m--> 225\u001b[0m k_embed \u001b[38;5;241m=\u001b[39m (\u001b[43mk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcos\u001b[49m) \u001b[38;5;241m+\u001b[39m (rotate_half(k) \u001b[38;5;241m*\u001b[39m sin)\n\u001b[1;32m    226\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m q_embed, k_embed\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Select a single conversation to test\n",
    "iloc = 493\n",
    "sample_conversation_id = 492\n",
    "sample_group = first_individual_turns_sorted[first_individual_turns_sorted[\"conversation_id\"] == sample_conversation_id]\n",
    "\n",
    "conversation_history = \"\"\n",
    "article = sample_group[\"article\"].iloc[0]\n",
    "\n",
    "print(f\"Running conversation ID: {sample_conversation_id}\\n\")\n",
    "\n",
    "for _, row in sample_group.iterrows():\n",
    "    latest_dialogue = row[\"text\"]\n",
    "    print(f\"Individual 1: {latest_dialogue}\\n awaiting response\")\n",
    "    model_response = query_model(article, conversation_history, latest_dialogue)\n",
    "    print(f\"Model: {model_response}\\n\")\n",
    "    \n",
    "    # Update conversation history\n",
    "    conversation_history += f\"Individual 1: {latest_dialogue}\\nModel: {model_response}\\n\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating normal responses to individual#1 dialogues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "currently processing 380th conversation\n",
      "currently processing 381th conversation\n",
      "currently processing 382th conversation\n",
      "currently processing 383th conversation\n",
      "currently processing 384th conversation\n",
      "currently processing 385th conversation\n",
      "Final results saved to /home/ajha/AP2/data/generated_conversations_llama_final.csv\n"
     ]
    }
   ],
   "source": [
    "# Initialize storage for the generated conversations\n",
    "conversation_results = []\n",
    "save_interval = 10\n",
    "\n",
    "# Process each conversation\n",
    "for i, (conversation_id, group) in enumerate(first_individual_turns_sorted.groupby(\"conversation_id\")):\n",
    "    print(f'currently processing {i}th conversation')\n",
    "    conversation_history = \"\"\n",
    "    article = group[\"article\"].iloc[0]\n",
    "    \n",
    "    for _, row in group.iterrows():\n",
    "        latest_dialogue = row[\"text\"]\n",
    "        model_response = query_model(article, conversation_history, latest_dialogue)\n",
    "        \n",
    "        # Update conversation history\n",
    "        conversation_history += f\"Individual 1: {latest_dialogue}\\nModel: {model_response}\\n\"\n",
    "        \n",
    "        # Store the conversation turn\n",
    "        conversation_results.append({\n",
    "            \"conversation_id\": conversation_id,\n",
    "            \"turn_id\": row[\"turn_id\"],\n",
    "            \"individual_1\": latest_dialogue,\n",
    "            \"model_response\": model_response,\n",
    "            \"article\": article\n",
    "        })\n",
    "    \n",
    "    # Save every 10 conversations\n",
    "    if (i + 1) % save_interval == 0:\n",
    "        temp_output_file = f\"/home/ajha/AP2/data/interim_data/generated_expressive_conversations_llama_part_{i // save_interval}.csv\"\n",
    "        pd.DataFrame(conversation_results).to_csv(temp_output_file, index=False)\n",
    "        print(f\"Intermediate results saved to {temp_output_file}\")\n",
    "        conversation_results = []  # Clear results after saving\n",
    "\n",
    "# Save any remaining results\n",
    "if conversation_results:\n",
    "    final_output_file = \"/home/ajha/AP2/data/generated_expressive_conversations_llama_final.csv\"\n",
    "    pd.DataFrame(conversation_results).to_csv(final_output_file, index=False)\n",
    "    print(f\"Final results saved to {final_output_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Expressive Conversations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "currently processing 0th conversation\n",
      "currently processing 1th conversation\n",
      "currently processing 2th conversation\n",
      "currently processing 3th conversation\n",
      "currently processing 4th conversation\n",
      "currently processing 5th conversation\n",
      "currently processing 6th conversation\n",
      "currently processing 7th conversation\n",
      "currently processing 8th conversation\n",
      "currently processing 9th conversation\n",
      "Appended results to /home/ajha/AP2/data/generated_expressive_conversations_llama_full.csv\n",
      "currently processing 10th conversation\n",
      "currently processing 11th conversation\n",
      "currently processing 12th conversation\n",
      "currently processing 13th conversation\n",
      "currently processing 14th conversation\n",
      "currently processing 15th conversation\n",
      "currently processing 16th conversation\n",
      "currently processing 17th conversation\n",
      "currently processing 18th conversation\n",
      "currently processing 19th conversation\n",
      "Appended results to /home/ajha/AP2/data/generated_expressive_conversations_llama_full.csv\n",
      "currently processing 20th conversation\n",
      "currently processing 21th conversation\n",
      "currently processing 22th conversation\n",
      "currently processing 23th conversation\n",
      "currently processing 24th conversation\n",
      "currently processing 25th conversation\n",
      "currently processing 26th conversation\n",
      "currently processing 27th conversation\n",
      "currently processing 28th conversation\n",
      "currently processing 29th conversation\n",
      "Appended results to /home/ajha/AP2/data/generated_expressive_conversations_llama_full.csv\n",
      "currently processing 30th conversation\n",
      "currently processing 31th conversation\n",
      "currently processing 32th conversation\n",
      "currently processing 33th conversation\n",
      "currently processing 34th conversation\n",
      "currently processing 35th conversation\n",
      "currently processing 36th conversation\n",
      "currently processing 37th conversation\n",
      "currently processing 38th conversation\n",
      "currently processing 39th conversation\n",
      "Appended results to /home/ajha/AP2/data/generated_expressive_conversations_llama_full.csv\n",
      "currently processing 40th conversation\n",
      "currently processing 41th conversation\n",
      "currently processing 42th conversation\n",
      "currently processing 43th conversation\n",
      "currently processing 44th conversation\n",
      "currently processing 45th conversation\n",
      "currently processing 46th conversation\n",
      "currently processing 47th conversation\n",
      "currently processing 48th conversation\n",
      "currently processing 49th conversation\n",
      "Appended results to /home/ajha/AP2/data/generated_expressive_conversations_llama_full.csv\n",
      "currently processing 50th conversation\n",
      "currently processing 51th conversation\n",
      "currently processing 52th conversation\n",
      "currently processing 53th conversation\n",
      "currently processing 54th conversation\n",
      "currently processing 55th conversation\n",
      "currently processing 56th conversation\n",
      "currently processing 57th conversation\n",
      "currently processing 58th conversation\n",
      "currently processing 59th conversation\n",
      "Appended results to /home/ajha/AP2/data/generated_expressive_conversations_llama_full.csv\n",
      "currently processing 60th conversation\n",
      "currently processing 61th conversation\n",
      "currently processing 62th conversation\n",
      "currently processing 63th conversation\n",
      "currently processing 64th conversation\n",
      "currently processing 65th conversation\n",
      "currently processing 66th conversation\n",
      "currently processing 67th conversation\n",
      "currently processing 68th conversation\n",
      "currently processing 69th conversation\n",
      "Appended results to /home/ajha/AP2/data/generated_expressive_conversations_llama_full.csv\n",
      "currently processing 70th conversation\n",
      "currently processing 71th conversation\n",
      "currently processing 72th conversation\n",
      "currently processing 73th conversation\n",
      "currently processing 74th conversation\n",
      "currently processing 75th conversation\n",
      "currently processing 76th conversation\n",
      "currently processing 77th conversation\n",
      "currently processing 78th conversation\n",
      "currently processing 79th conversation\n",
      "Appended results to /home/ajha/AP2/data/generated_expressive_conversations_llama_full.csv\n",
      "currently processing 80th conversation\n",
      "currently processing 81th conversation\n",
      "currently processing 82th conversation\n",
      "currently processing 83th conversation\n",
      "currently processing 84th conversation\n",
      "currently processing 85th conversation\n",
      "currently processing 86th conversation\n",
      "currently processing 87th conversation\n",
      "currently processing 88th conversation\n",
      "currently processing 89th conversation\n",
      "Appended results to /home/ajha/AP2/data/generated_expressive_conversations_llama_full.csv\n",
      "currently processing 90th conversation\n",
      "currently processing 91th conversation\n",
      "currently processing 92th conversation\n",
      "currently processing 93th conversation\n",
      "currently processing 94th conversation\n",
      "currently processing 95th conversation\n",
      "currently processing 96th conversation\n",
      "currently processing 97th conversation\n",
      "currently processing 98th conversation\n",
      "currently processing 99th conversation\n",
      "Appended results to /home/ajha/AP2/data/generated_expressive_conversations_llama_full.csv\n",
      "currently processing 100th conversation\n",
      "currently processing 101th conversation\n",
      "currently processing 102th conversation\n",
      "currently processing 103th conversation\n",
      "currently processing 104th conversation\n",
      "currently processing 105th conversation\n",
      "currently processing 106th conversation\n",
      "currently processing 107th conversation\n",
      "currently processing 108th conversation\n",
      "currently processing 109th conversation\n",
      "Appended results to /home/ajha/AP2/data/generated_expressive_conversations_llama_full.csv\n",
      "currently processing 110th conversation\n",
      "currently processing 111th conversation\n",
      "currently processing 112th conversation\n",
      "currently processing 113th conversation\n",
      "currently processing 114th conversation\n",
      "currently processing 115th conversation\n",
      "currently processing 116th conversation\n",
      "currently processing 117th conversation\n",
      "currently processing 118th conversation\n",
      "currently processing 119th conversation\n",
      "Appended results to /home/ajha/AP2/data/generated_expressive_conversations_llama_full.csv\n",
      "currently processing 120th conversation\n",
      "currently processing 121th conversation\n",
      "currently processing 122th conversation\n",
      "currently processing 123th conversation\n",
      "currently processing 124th conversation\n",
      "currently processing 125th conversation\n",
      "currently processing 126th conversation\n",
      "currently processing 127th conversation\n",
      "currently processing 128th conversation\n",
      "currently processing 129th conversation\n",
      "Appended results to /home/ajha/AP2/data/generated_expressive_conversations_llama_full.csv\n",
      "currently processing 130th conversation\n",
      "currently processing 131th conversation\n",
      "currently processing 132th conversation\n",
      "currently processing 133th conversation\n",
      "currently processing 134th conversation\n",
      "currently processing 135th conversation\n",
      "currently processing 136th conversation\n",
      "currently processing 137th conversation\n",
      "currently processing 138th conversation\n",
      "currently processing 139th conversation\n",
      "Appended results to /home/ajha/AP2/data/generated_expressive_conversations_llama_full.csv\n",
      "currently processing 140th conversation\n",
      "currently processing 141th conversation\n",
      "currently processing 142th conversation\n",
      "currently processing 143th conversation\n",
      "currently processing 144th conversation\n",
      "currently processing 145th conversation\n",
      "currently processing 146th conversation\n",
      "currently processing 147th conversation\n",
      "currently processing 148th conversation\n",
      "currently processing 149th conversation\n",
      "Appended results to /home/ajha/AP2/data/generated_expressive_conversations_llama_full.csv\n",
      "currently processing 150th conversation\n",
      "currently processing 151th conversation\n",
      "currently processing 152th conversation\n",
      "currently processing 153th conversation\n",
      "currently processing 154th conversation\n",
      "currently processing 155th conversation\n",
      "currently processing 156th conversation\n",
      "currently processing 157th conversation\n",
      "currently processing 158th conversation\n",
      "currently processing 159th conversation\n",
      "Appended results to /home/ajha/AP2/data/generated_expressive_conversations_llama_full.csv\n",
      "currently processing 160th conversation\n",
      "currently processing 161th conversation\n",
      "currently processing 162th conversation\n",
      "currently processing 163th conversation\n",
      "currently processing 164th conversation\n",
      "currently processing 165th conversation\n",
      "currently processing 166th conversation\n",
      "currently processing 167th conversation\n",
      "currently processing 168th conversation\n",
      "currently processing 169th conversation\n",
      "Appended results to /home/ajha/AP2/data/generated_expressive_conversations_llama_full.csv\n",
      "currently processing 170th conversation\n",
      "currently processing 171th conversation\n",
      "currently processing 172th conversation\n",
      "currently processing 173th conversation\n",
      "currently processing 174th conversation\n",
      "currently processing 175th conversation\n",
      "currently processing 176th conversation\n",
      "currently processing 177th conversation\n",
      "currently processing 178th conversation\n",
      "currently processing 179th conversation\n",
      "Appended results to /home/ajha/AP2/data/generated_expressive_conversations_llama_full.csv\n",
      "currently processing 180th conversation\n",
      "currently processing 181th conversation\n",
      "currently processing 182th conversation\n",
      "currently processing 183th conversation\n",
      "currently processing 184th conversation\n",
      "currently processing 185th conversation\n",
      "currently processing 186th conversation\n",
      "currently processing 187th conversation\n",
      "currently processing 188th conversation\n",
      "currently processing 189th conversation\n",
      "Appended results to /home/ajha/AP2/data/generated_expressive_conversations_llama_full.csv\n",
      "currently processing 190th conversation\n",
      "currently processing 191th conversation\n",
      "currently processing 192th conversation\n",
      "currently processing 193th conversation\n",
      "currently processing 194th conversation\n",
      "currently processing 195th conversation\n",
      "currently processing 196th conversation\n",
      "currently processing 197th conversation\n",
      "currently processing 198th conversation\n",
      "currently processing 199th conversation\n",
      "Appended results to /home/ajha/AP2/data/generated_expressive_conversations_llama_full.csv\n",
      "currently processing 200th conversation\n",
      "currently processing 201th conversation\n",
      "currently processing 202th conversation\n",
      "currently processing 203th conversation\n",
      "currently processing 204th conversation\n",
      "currently processing 205th conversation\n",
      "currently processing 206th conversation\n",
      "currently processing 207th conversation\n",
      "currently processing 208th conversation\n",
      "currently processing 209th conversation\n",
      "Appended results to /home/ajha/AP2/data/generated_expressive_conversations_llama_full.csv\n",
      "currently processing 210th conversation\n",
      "currently processing 211th conversation\n",
      "currently processing 212th conversation\n",
      "currently processing 213th conversation\n",
      "currently processing 214th conversation\n",
      "currently processing 215th conversation\n",
      "currently processing 216th conversation\n",
      "currently processing 217th conversation\n",
      "currently processing 218th conversation\n",
      "currently processing 219th conversation\n",
      "Appended results to /home/ajha/AP2/data/generated_expressive_conversations_llama_full.csv\n",
      "currently processing 220th conversation\n",
      "currently processing 221th conversation\n",
      "currently processing 222th conversation\n",
      "currently processing 223th conversation\n",
      "currently processing 224th conversation\n",
      "currently processing 225th conversation\n",
      "currently processing 226th conversation\n",
      "currently processing 227th conversation\n",
      "currently processing 228th conversation\n",
      "currently processing 229th conversation\n",
      "Appended results to /home/ajha/AP2/data/generated_expressive_conversations_llama_full.csv\n",
      "currently processing 230th conversation\n",
      "currently processing 231th conversation\n",
      "currently processing 232th conversation\n",
      "currently processing 233th conversation\n",
      "currently processing 234th conversation\n",
      "currently processing 235th conversation\n",
      "currently processing 236th conversation\n",
      "currently processing 237th conversation\n",
      "currently processing 238th conversation\n",
      "currently processing 239th conversation\n",
      "Appended results to /home/ajha/AP2/data/generated_expressive_conversations_llama_full.csv\n",
      "currently processing 240th conversation\n",
      "currently processing 241th conversation\n",
      "currently processing 242th conversation\n",
      "currently processing 243th conversation\n",
      "currently processing 244th conversation\n",
      "currently processing 245th conversation\n",
      "currently processing 246th conversation\n",
      "currently processing 247th conversation\n",
      "currently processing 248th conversation\n",
      "currently processing 249th conversation\n",
      "Appended results to /home/ajha/AP2/data/generated_expressive_conversations_llama_full.csv\n",
      "currently processing 250th conversation\n",
      "currently processing 251th conversation\n",
      "currently processing 252th conversation\n",
      "currently processing 253th conversation\n",
      "currently processing 254th conversation\n",
      "currently processing 255th conversation\n",
      "currently processing 256th conversation\n",
      "currently processing 257th conversation\n",
      "currently processing 258th conversation\n",
      "currently processing 259th conversation\n",
      "Appended results to /home/ajha/AP2/data/generated_expressive_conversations_llama_full.csv\n",
      "currently processing 260th conversation\n",
      "currently processing 261th conversation\n",
      "currently processing 262th conversation\n",
      "currently processing 263th conversation\n",
      "currently processing 264th conversation\n",
      "currently processing 265th conversation\n",
      "currently processing 266th conversation\n",
      "currently processing 267th conversation\n",
      "currently processing 268th conversation\n",
      "currently processing 269th conversation\n",
      "Appended results to /home/ajha/AP2/data/generated_expressive_conversations_llama_full.csv\n",
      "currently processing 270th conversation\n",
      "currently processing 271th conversation\n",
      "currently processing 272th conversation\n",
      "currently processing 273th conversation\n",
      "currently processing 274th conversation\n",
      "currently processing 275th conversation\n",
      "currently processing 276th conversation\n",
      "currently processing 277th conversation\n",
      "currently processing 278th conversation\n",
      "currently processing 279th conversation\n",
      "Appended results to /home/ajha/AP2/data/generated_expressive_conversations_llama_full.csv\n",
      "currently processing 280th conversation\n",
      "currently processing 281th conversation\n",
      "currently processing 282th conversation\n",
      "currently processing 283th conversation\n",
      "currently processing 284th conversation\n",
      "currently processing 285th conversation\n",
      "currently processing 286th conversation\n",
      "currently processing 287th conversation\n",
      "currently processing 288th conversation\n",
      "currently processing 289th conversation\n",
      "Appended results to /home/ajha/AP2/data/generated_expressive_conversations_llama_full.csv\n",
      "currently processing 290th conversation\n",
      "currently processing 291th conversation\n",
      "currently processing 292th conversation\n",
      "currently processing 293th conversation\n",
      "currently processing 294th conversation\n",
      "currently processing 295th conversation\n",
      "currently processing 296th conversation\n",
      "currently processing 297th conversation\n",
      "currently processing 298th conversation\n",
      "currently processing 299th conversation\n",
      "Appended results to /home/ajha/AP2/data/generated_expressive_conversations_llama_full.csv\n",
      "currently processing 300th conversation\n",
      "currently processing 301th conversation\n",
      "currently processing 302th conversation\n",
      "currently processing 303th conversation\n",
      "currently processing 304th conversation\n",
      "currently processing 305th conversation\n",
      "currently processing 306th conversation\n",
      "currently processing 307th conversation\n",
      "currently processing 308th conversation\n",
      "currently processing 309th conversation\n",
      "Appended results to /home/ajha/AP2/data/generated_expressive_conversations_llama_full.csv\n",
      "currently processing 310th conversation\n",
      "currently processing 311th conversation\n",
      "currently processing 312th conversation\n",
      "currently processing 313th conversation\n",
      "currently processing 314th conversation\n",
      "currently processing 315th conversation\n",
      "currently processing 316th conversation\n",
      "currently processing 317th conversation\n",
      "currently processing 318th conversation\n",
      "currently processing 319th conversation\n",
      "Appended results to /home/ajha/AP2/data/generated_expressive_conversations_llama_full.csv\n",
      "currently processing 320th conversation\n",
      "currently processing 321th conversation\n",
      "currently processing 322th conversation\n",
      "currently processing 323th conversation\n",
      "currently processing 324th conversation\n",
      "currently processing 325th conversation\n",
      "currently processing 326th conversation\n",
      "currently processing 327th conversation\n",
      "currently processing 328th conversation\n",
      "currently processing 329th conversation\n",
      "Appended results to /home/ajha/AP2/data/generated_expressive_conversations_llama_full.csv\n",
      "currently processing 330th conversation\n",
      "currently processing 331th conversation\n",
      "currently processing 332th conversation\n",
      "currently processing 333th conversation\n",
      "currently processing 334th conversation\n",
      "currently processing 335th conversation\n",
      "currently processing 336th conversation\n",
      "currently processing 337th conversation\n",
      "currently processing 338th conversation\n",
      "currently processing 339th conversation\n",
      "Appended results to /home/ajha/AP2/data/generated_expressive_conversations_llama_full.csv\n",
      "currently processing 340th conversation\n",
      "currently processing 341th conversation\n",
      "currently processing 342th conversation\n",
      "currently processing 343th conversation\n",
      "currently processing 344th conversation\n",
      "currently processing 345th conversation\n",
      "currently processing 346th conversation\n",
      "currently processing 347th conversation\n",
      "currently processing 348th conversation\n",
      "currently processing 349th conversation\n",
      "Appended results to /home/ajha/AP2/data/generated_expressive_conversations_llama_full.csv\n",
      "currently processing 350th conversation\n",
      "currently processing 351th conversation\n",
      "currently processing 352th conversation\n",
      "currently processing 353th conversation\n",
      "currently processing 354th conversation\n",
      "currently processing 355th conversation\n",
      "currently processing 356th conversation\n",
      "currently processing 357th conversation\n",
      "currently processing 358th conversation\n",
      "currently processing 359th conversation\n",
      "Appended results to /home/ajha/AP2/data/generated_expressive_conversations_llama_full.csv\n",
      "currently processing 360th conversation\n",
      "currently processing 361th conversation\n",
      "currently processing 362th conversation\n",
      "currently processing 363th conversation\n",
      "currently processing 364th conversation\n",
      "currently processing 365th conversation\n",
      "currently processing 366th conversation\n",
      "currently processing 367th conversation\n",
      "currently processing 368th conversation\n",
      "currently processing 369th conversation\n",
      "Appended results to /home/ajha/AP2/data/generated_expressive_conversations_llama_full.csv\n",
      "currently processing 370th conversation\n",
      "currently processing 371th conversation\n",
      "currently processing 372th conversation\n",
      "currently processing 373th conversation\n",
      "currently processing 374th conversation\n",
      "currently processing 375th conversation\n",
      "currently processing 376th conversation\n",
      "currently processing 377th conversation\n",
      "currently processing 378th conversation\n",
      "currently processing 379th conversation\n",
      "Appended results to /home/ajha/AP2/data/generated_expressive_conversations_llama_full.csv\n",
      "currently processing 380th conversation\n",
      "currently processing 381th conversation\n",
      "currently processing 382th conversation\n",
      "currently processing 383th conversation\n",
      "currently processing 384th conversation\n",
      "currently processing 385th conversation\n",
      "Final results appended to /home/ajha/AP2/data/generated_expressive_conversations_llama_full.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "conversation_results = []\n",
    "save_interval = 10\n",
    "output_file = \"/home/ajha/AP2/data/generated_expressive_conversations_llama_full.csv\"\n",
    "\n",
    "file_exists = os.path.exists(output_file)\n",
    "\n",
    "# Process each conversation\n",
    "for i, (conversation_id, group) in enumerate(first_individual_turns_sorted.groupby(\"conversation_id\")):\n",
    "    print(f'currently processing {i}th conversation')\n",
    "    conversation_history = \"\"\n",
    "    article = group[\"article\"].iloc[0]\n",
    "    \n",
    "    for _, row in group.iterrows():\n",
    "        latest_dialogue = row[\"text\"]\n",
    "        model_response = query_model(article, conversation_history, latest_dialogue)\n",
    "        \n",
    "        # Update conversation history\n",
    "        conversation_history += f\"Individual 1: {latest_dialogue}\\nModel: {model_response}\\n\"\n",
    "        \n",
    "        # Store the conversation turn\n",
    "        conversation_results.append({\n",
    "            \"conversation_id\": conversation_id,\n",
    "            \"turn_id\": row[\"turn_id\"],\n",
    "            \"individual_1\": latest_dialogue,\n",
    "            \"model_response\": model_response,\n",
    "            \"article\": article\n",
    "        })\n",
    "    \n",
    "    # Append every 10 conversations\n",
    "    if (i + 1) % save_interval == 0:\n",
    "        pd.DataFrame(conversation_results).to_csv(\n",
    "            output_file,\n",
    "            mode='a',\n",
    "            index=False,\n",
    "            header=not file_exists  # Write header only once\n",
    "        )\n",
    "        file_exists = True\n",
    "        print(f\"Appended results to {output_file}\")\n",
    "        conversation_results = []  # Clear results after saving\n",
    "\n",
    "# Save any remaining results\n",
    "if conversation_results:\n",
    "    pd.DataFrame(conversation_results).to_csv(\n",
    "        output_file,\n",
    "        mode='a',\n",
    "        index=False,\n",
    "        header=not file_exists\n",
    "    )\n",
    "    print(f\"Final results appended to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### combining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "\n",
    "# Path to directory\n",
    "base_path = \"/home/ajha/AP2/data/interim_data\"\n",
    "\n",
    "# Get all part_*.csv files\n",
    "part_files = sorted(glob.glob(os.path.join(base_path, \"generated_conversations_llama_part_*.csv\")))\n",
    "\n",
    "# Add the final file\n",
    "part_files.append(os.path.join(base_path, \"generated_conversations_llama_final.csv\"))\n",
    "\n",
    "# Read and concatenate\n",
    "df_all = pd.concat((pd.read_csv(f) for f in part_files), ignore_index=True)\n",
    "\n",
    "# Save combined file\n",
    "df_all.to_csv(os.path.join(base_path, \"generated_conversations_llama_combined.csv\"), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = pd.read_csv('/home/ajha/AP2/data/interim_data/generated_conversations_llama_combined.csv')\n",
    "actual_df = pd.read_csv('/home/ajha/AP2/data/WASSA23_conv_level_with_labels_train.tsv', delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conversation_id</th>\n",
       "      <th>turn_id</th>\n",
       "      <th>individual_1</th>\n",
       "      <th>model_response</th>\n",
       "      <th>article</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>I feel very sad for the people.</td>\n",
       "      <td>Me too, it's heartbreaking to see families str...</td>\n",
       "      <td>A month after Hurricane Matthew, 800,000 Haiti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Yeah, the whole situation is horrible.</td>\n",
       "      <td>And the fact that there's a lack of coordinati...</td>\n",
       "      <td>A month after Hurricane Matthew, 800,000 Haiti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>I know we can donate, but it's hard to know ex...</td>\n",
       "      <td>I completely understand. It's frustrating when...</td>\n",
       "      <td>A month after Hurricane Matthew, 800,000 Haiti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>No, and You?</td>\n",
       "      <td>I completely agree, it's frustrating when we d...</td>\n",
       "      <td>A month after Hurricane Matthew, 800,000 Haiti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>Sorry to hear that, I'm glad that you are okay!</td>\n",
       "      <td>Yeah, I'm good, just trying to process what's ...</td>\n",
       "      <td>A month after Hurricane Matthew, 800,000 Haiti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4450</th>\n",
       "      <td>500</td>\n",
       "      <td>12</td>\n",
       "      <td>I have never fell while drinking have you?</td>\n",
       "      <td>No, fortunately not! But I've heard it's a pos...</td>\n",
       "      <td>Death of former Putin aide at D.C. hotel is ru...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4451</th>\n",
       "      <td>500</td>\n",
       "      <td>14</td>\n",
       "      <td>Yeah it could have been murder</td>\n",
       "      <td>That's definitely a possibility, especially gi...</td>\n",
       "      <td>Death of former Putin aide at D.C. hotel is ru...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4452</th>\n",
       "      <td>500</td>\n",
       "      <td>16</td>\n",
       "      <td>Do you think maybe he was force to kill himself</td>\n",
       "      <td>It's possible, the article mentions that he wa...</td>\n",
       "      <td>Death of former Putin aide at D.C. hotel is ru...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4453</th>\n",
       "      <td>500</td>\n",
       "      <td>18</td>\n",
       "      <td>Or he could have slipped on something. Either ...</td>\n",
       "      <td>I know, it's sad. He was a pretty influential ...</td>\n",
       "      <td>Death of former Putin aide at D.C. hotel is ru...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4454</th>\n",
       "      <td>500</td>\n",
       "      <td>20</td>\n",
       "      <td>ok thank you. bye!</td>\n",
       "      <td>No problem, nice chatting with you.</td>\n",
       "      <td>Death of former Putin aide at D.C. hotel is ru...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4455 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      conversation_id  turn_id  \\\n",
       "0                   2        0   \n",
       "1                   2        2   \n",
       "2                   2        4   \n",
       "3                   2        6   \n",
       "4                   2        8   \n",
       "...               ...      ...   \n",
       "4450              500       12   \n",
       "4451              500       14   \n",
       "4452              500       16   \n",
       "4453              500       18   \n",
       "4454              500       20   \n",
       "\n",
       "                                           individual_1  \\\n",
       "0                       I feel very sad for the people.   \n",
       "1                Yeah, the whole situation is horrible.   \n",
       "2     I know we can donate, but it's hard to know ex...   \n",
       "3                                          No, and You?   \n",
       "4       Sorry to hear that, I'm glad that you are okay!   \n",
       "...                                                 ...   \n",
       "4450         I have never fell while drinking have you?   \n",
       "4451                     Yeah it could have been murder   \n",
       "4452    Do you think maybe he was force to kill himself   \n",
       "4453  Or he could have slipped on something. Either ...   \n",
       "4454                                 ok thank you. bye!   \n",
       "\n",
       "                                         model_response  \\\n",
       "0     Me too, it's heartbreaking to see families str...   \n",
       "1     And the fact that there's a lack of coordinati...   \n",
       "2     I completely understand. It's frustrating when...   \n",
       "3     I completely agree, it's frustrating when we d...   \n",
       "4     Yeah, I'm good, just trying to process what's ...   \n",
       "...                                                 ...   \n",
       "4450  No, fortunately not! But I've heard it's a pos...   \n",
       "4451  That's definitely a possibility, especially gi...   \n",
       "4452  It's possible, the article mentions that he wa...   \n",
       "4453  I know, it's sad. He was a pretty influential ...   \n",
       "4454                No problem, nice chatting with you.   \n",
       "\n",
       "                                                article  \n",
       "0     A month after Hurricane Matthew, 800,000 Haiti...  \n",
       "1     A month after Hurricane Matthew, 800,000 Haiti...  \n",
       "2     A month after Hurricane Matthew, 800,000 Haiti...  \n",
       "3     A month after Hurricane Matthew, 800,000 Haiti...  \n",
       "4     A month after Hurricane Matthew, 800,000 Haiti...  \n",
       "...                                                 ...  \n",
       "4450  Death of former Putin aide at D.C. hotel is ru...  \n",
       "4451  Death of former Putin aide at D.C. hotel is ru...  \n",
       "4452  Death of former Putin aide at D.C. hotel is ru...  \n",
       "4453  Death of former Putin aide at D.C. hotel is ru...  \n",
       "4454  Death of former Putin aide at D.C. hotel is ru...  \n",
       "\n",
       "[4455 rows x 5 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average number of words per turn: 26.73\n"
     ]
    }
   ],
   "source": [
    "# Compute average word count for each column\n",
    "avg_individual = combined_df['individual_1'].apply(lambda x: len(str(x).split())).mean()\n",
    "avg_model = combined_df['model_response'].apply(lambda x: len(str(x).split())).mean()\n",
    "\n",
    "# Final averaged result\n",
    "avg_words_per_turn = (avg_individual + avg_model) / 2\n",
    "\n",
    "print(f\"Average number of words per turn: {avg_words_per_turn:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conversation_id</th>\n",
       "      <th>turn_id</th>\n",
       "      <th>text</th>\n",
       "      <th>EmotionalPolarity</th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Empathy</th>\n",
       "      <th>speaker_number</th>\n",
       "      <th>article_id</th>\n",
       "      <th>speaker_id</th>\n",
       "      <th>essay_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>I feel very sad for the people.</td>\n",
       "      <td>2.0000</td>\n",
       "      <td>3.0000</td>\n",
       "      <td>3.3333</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>It's terrible. Not only the people but the ani...</td>\n",
       "      <td>2.0000</td>\n",
       "      <td>4.0000</td>\n",
       "      <td>3.3333</td>\n",
       "      <td>2</td>\n",
       "      <td>35.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>501.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>I felt really sorry for the sister that now ha...</td>\n",
       "      <td>2.0000</td>\n",
       "      <td>3.6667</td>\n",
       "      <td>2.6667</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>Yeah, it's going to be tough but i am sure she...</td>\n",
       "      <td>0.6667</td>\n",
       "      <td>3.0000</td>\n",
       "      <td>2.0000</td>\n",
       "      <td>2</td>\n",
       "      <td>35.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>501.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>Yeah, we never know what we can do unless we a...</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>2.3333</td>\n",
       "      <td>1.3333</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8771</th>\n",
       "      <td>58</td>\n",
       "      <td>5</td>\n",
       "      <td>I'm sure that would go a long way. It's at lea...</td>\n",
       "      <td>2.0000</td>\n",
       "      <td>3.0000</td>\n",
       "      <td>3.0000</td>\n",
       "      <td>2</td>\n",
       "      <td>72.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>557.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8772</th>\n",
       "      <td>58</td>\n",
       "      <td>6</td>\n",
       "      <td>Oh exactly, it always comes down to the money....</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>2.0000</td>\n",
       "      <td>2.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>72.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>57.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8773</th>\n",
       "      <td>58</td>\n",
       "      <td>7</td>\n",
       "      <td>And when it's the officials who are getting pa...</td>\n",
       "      <td>2.0000</td>\n",
       "      <td>2.0000</td>\n",
       "      <td>2.0000</td>\n",
       "      <td>2</td>\n",
       "      <td>72.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>557.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8774</th>\n",
       "      <td>58</td>\n",
       "      <td>8</td>\n",
       "      <td>Yes corruption I'm sure is very huge. It has t...</td>\n",
       "      <td>2.0000</td>\n",
       "      <td>3.0000</td>\n",
       "      <td>3.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>72.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>57.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8775</th>\n",
       "      <td>58</td>\n",
       "      <td>9</td>\n",
       "      <td>I think if the west took more of an interest i...</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>2.0000</td>\n",
       "      <td>3.0000</td>\n",
       "      <td>2</td>\n",
       "      <td>72.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>557.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8776 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      conversation_id  turn_id  \\\n",
       "0                   2        0   \n",
       "1                   2        1   \n",
       "2                   2       10   \n",
       "3                   2       11   \n",
       "4                   2       12   \n",
       "...               ...      ...   \n",
       "8771               58        5   \n",
       "8772               58        6   \n",
       "8773               58        7   \n",
       "8774               58        8   \n",
       "8775               58        9   \n",
       "\n",
       "                                                   text  EmotionalPolarity  \\\n",
       "0                       I feel very sad for the people.             2.0000   \n",
       "1     It's terrible. Not only the people but the ani...             2.0000   \n",
       "2     I felt really sorry for the sister that now ha...             2.0000   \n",
       "3     Yeah, it's going to be tough but i am sure she...             0.6667   \n",
       "4     Yeah, we never know what we can do unless we a...             0.3333   \n",
       "...                                                 ...                ...   \n",
       "8771  I'm sure that would go a long way. It's at lea...             2.0000   \n",
       "8772  Oh exactly, it always comes down to the money....             0.0000   \n",
       "8773  And when it's the officials who are getting pa...             2.0000   \n",
       "8774  Yes corruption I'm sure is very huge. It has t...             2.0000   \n",
       "8775  I think if the west took more of an interest i...             1.0000   \n",
       "\n",
       "      Emotion  Empathy  speaker_number  article_id  speaker_id  essay_id  \n",
       "0      3.0000   3.3333               1        35.0        30.0       1.0  \n",
       "1      4.0000   3.3333               2        35.0        17.0     501.0  \n",
       "2      3.6667   2.6667               1        35.0        30.0       1.0  \n",
       "3      3.0000   2.0000               2        35.0        17.0     501.0  \n",
       "4      2.3333   1.3333               1        35.0        30.0       1.0  \n",
       "...       ...      ...             ...         ...         ...       ...  \n",
       "8771   3.0000   3.0000               2        72.0        46.0     557.0  \n",
       "8772   2.0000   2.0000               1        72.0        44.0      57.0  \n",
       "8773   2.0000   2.0000               2        72.0        46.0     557.0  \n",
       "8774   3.0000   3.0000               1        72.0        44.0      57.0  \n",
       "8775   2.0000   3.0000               2        72.0        46.0     557.0  \n",
       "\n",
       "[8776 rows x 10 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actual_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average number of words per turn: 17.98\n"
     ]
    }
   ],
   "source": [
    "# Compute average number of words per turn\n",
    "avg_words = actual_df['text'].apply(lambda x: len(str(x).split())).mean()\n",
    "\n",
    "print(f\"Average number of words per turn: {avg_words:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## combining turns to avoid sparsity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "expressive_hl_df = pd.read_csv('/home/ajha/AP2/data/generated_expressive_conversations_llama_full.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conversation_id</th>\n",
       "      <th>turn_id</th>\n",
       "      <th>individual_1</th>\n",
       "      <th>model_response</th>\n",
       "      <th>article</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>I feel very sad for the people.</td>\n",
       "      <td>I know, it's heartbreaking. The images of the ...</td>\n",
       "      <td>A month after Hurricane Matthew, 800,000 Haiti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Yeah, the whole situation is horrible.</td>\n",
       "      <td>It's absolutely tragic. The way the storm hit ...</td>\n",
       "      <td>A month after Hurricane Matthew, 800,000 Haiti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>I know we can donate, but it's hard to know ex...</td>\n",
       "      <td>I completely understand your concern. It's nat...</td>\n",
       "      <td>A month after Hurricane Matthew, 800,000 Haiti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>No, and You?</td>\n",
       "      <td>I know, it's frustrating to not know exactly h...</td>\n",
       "      <td>A month after Hurricane Matthew, 800,000 Haiti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>Sorry to hear that, I'm glad that you are okay!</td>\n",
       "      <td>I'm still trying to process the scale of the d...</td>\n",
       "      <td>A month after Hurricane Matthew, 800,000 Haiti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4450</th>\n",
       "      <td>500</td>\n",
       "      <td>12</td>\n",
       "      <td>I have never fell while drinking have you?</td>\n",
       "      <td>No, I'm a bit clumsy sometimes, but I've never...</td>\n",
       "      <td>Death of former Putin aide at D.C. hotel is ru...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4451</th>\n",
       "      <td>500</td>\n",
       "      <td>14</td>\n",
       "      <td>Yeah it could have been murder</td>\n",
       "      <td>I know, it's easy to get caught up in conspira...</td>\n",
       "      <td>Death of former Putin aide at D.C. hotel is ru...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4452</th>\n",
       "      <td>500</td>\n",
       "      <td>16</td>\n",
       "      <td>Do you think maybe he was force to kill himself</td>\n",
       "      <td>I understand why you'd think that, given the p...</td>\n",
       "      <td>Death of former Putin aide at D.C. hotel is ru...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4453</th>\n",
       "      <td>500</td>\n",
       "      <td>18</td>\n",
       "      <td>Or he could have slipped on something. Either ...</td>\n",
       "      <td>I know, it's a shame that his life ended in su...</td>\n",
       "      <td>Death of former Putin aide at D.C. hotel is ru...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4454</th>\n",
       "      <td>500</td>\n",
       "      <td>20</td>\n",
       "      <td>ok thank you. bye!</td>\n",
       "      <td>it was a good conversation. I'm glad we could ...</td>\n",
       "      <td>Death of former Putin aide at D.C. hotel is ru...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4455 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      conversation_id  turn_id  \\\n",
       "0                   2        0   \n",
       "1                   2        2   \n",
       "2                   2        4   \n",
       "3                   2        6   \n",
       "4                   2        8   \n",
       "...               ...      ...   \n",
       "4450              500       12   \n",
       "4451              500       14   \n",
       "4452              500       16   \n",
       "4453              500       18   \n",
       "4454              500       20   \n",
       "\n",
       "                                           individual_1  \\\n",
       "0                       I feel very sad for the people.   \n",
       "1                Yeah, the whole situation is horrible.   \n",
       "2     I know we can donate, but it's hard to know ex...   \n",
       "3                                          No, and You?   \n",
       "4       Sorry to hear that, I'm glad that you are okay!   \n",
       "...                                                 ...   \n",
       "4450         I have never fell while drinking have you?   \n",
       "4451                     Yeah it could have been murder   \n",
       "4452    Do you think maybe he was force to kill himself   \n",
       "4453  Or he could have slipped on something. Either ...   \n",
       "4454                                 ok thank you. bye!   \n",
       "\n",
       "                                         model_response  \\\n",
       "0     I know, it's heartbreaking. The images of the ...   \n",
       "1     It's absolutely tragic. The way the storm hit ...   \n",
       "2     I completely understand your concern. It's nat...   \n",
       "3     I know, it's frustrating to not know exactly h...   \n",
       "4     I'm still trying to process the scale of the d...   \n",
       "...                                                 ...   \n",
       "4450  No, I'm a bit clumsy sometimes, but I've never...   \n",
       "4451  I know, it's easy to get caught up in conspira...   \n",
       "4452  I understand why you'd think that, given the p...   \n",
       "4453  I know, it's a shame that his life ended in su...   \n",
       "4454  it was a good conversation. I'm glad we could ...   \n",
       "\n",
       "                                                article  \n",
       "0     A month after Hurricane Matthew, 800,000 Haiti...  \n",
       "1     A month after Hurricane Matthew, 800,000 Haiti...  \n",
       "2     A month after Hurricane Matthew, 800,000 Haiti...  \n",
       "3     A month after Hurricane Matthew, 800,000 Haiti...  \n",
       "4     A month after Hurricane Matthew, 800,000 Haiti...  \n",
       "...                                                 ...  \n",
       "4450  Death of former Putin aide at D.C. hotel is ru...  \n",
       "4451  Death of former Putin aide at D.C. hotel is ru...  \n",
       "4452  Death of former Putin aide at D.C. hotel is ru...  \n",
       "4453  Death of former Putin aide at D.C. hotel is ru...  \n",
       "4454  Death of former Putin aide at D.C. hotel is ru...  \n",
       "\n",
       "[4455 rows x 5 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expressive_hl_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conversation_id</th>\n",
       "      <th>turn_id</th>\n",
       "      <th>article</th>\n",
       "      <th>speaker</th>\n",
       "      <th>utterance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>A month after Hurricane Matthew, 800,000 Haiti...</td>\n",
       "      <td>individual_1</td>\n",
       "      <td>I feel very sad for the people.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>A month after Hurricane Matthew, 800,000 Haiti...</td>\n",
       "      <td>model</td>\n",
       "      <td>I know, it's heartbreaking. The images of the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>A month after Hurricane Matthew, 800,000 Haiti...</td>\n",
       "      <td>individual_1</td>\n",
       "      <td>Yeah, the whole situation is horrible.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>A month after Hurricane Matthew, 800,000 Haiti...</td>\n",
       "      <td>model</td>\n",
       "      <td>It's absolutely tragic. The way the storm hit ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>A month after Hurricane Matthew, 800,000 Haiti...</td>\n",
       "      <td>individual_1</td>\n",
       "      <td>I know we can donate, but it's hard to know ex...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   conversation_id  turn_id  \\\n",
       "0                2        0   \n",
       "1                2        0   \n",
       "2                2        2   \n",
       "3                2        2   \n",
       "4                2        4   \n",
       "\n",
       "                                             article       speaker  \\\n",
       "0  A month after Hurricane Matthew, 800,000 Haiti...  individual_1   \n",
       "1  A month after Hurricane Matthew, 800,000 Haiti...         model   \n",
       "2  A month after Hurricane Matthew, 800,000 Haiti...  individual_1   \n",
       "3  A month after Hurricane Matthew, 800,000 Haiti...         model   \n",
       "4  A month after Hurricane Matthew, 800,000 Haiti...  individual_1   \n",
       "\n",
       "                                           utterance  \n",
       "0                    I feel very sad for the people.  \n",
       "1  I know, it's heartbreaking. The images of the ...  \n",
       "2             Yeah, the whole situation is horrible.  \n",
       "3  It's absolutely tragic. The way the storm hit ...  \n",
       "4  I know we can donate, but it's hard to know ex...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Step 1: Melt the wide columns into long format\n",
    "df_long = pd.melt(\n",
    "    expressive_hl_df,\n",
    "    id_vars=['conversation_id', 'turn_id', 'article'],\n",
    "    value_vars=['individual_1', 'model_response'],\n",
    "    var_name='speaker',\n",
    "    value_name='utterance'\n",
    ")\n",
    "\n",
    "\n",
    "speaker_order = {'individual_1': 0, 'model_response': 1}\n",
    "df_long['speaker_order'] = df_long['speaker'].map(speaker_order)\n",
    "df_long = df_long.sort_values(by=['conversation_id', 'turn_id', 'speaker_order'])\n",
    "\n",
    "\n",
    "df_long['speaker'] = df_long['speaker'].replace({'model_response': 'model'})\n",
    "\n",
    "\n",
    "df_long = df_long.drop(columns='speaker_order').reset_index(drop=True)\n",
    "\n",
    "df_long.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conversation_id</th>\n",
       "      <th>turn_id</th>\n",
       "      <th>article</th>\n",
       "      <th>speaker</th>\n",
       "      <th>utterance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>A month after Hurricane Matthew, 800,000 Haiti...</td>\n",
       "      <td>individual_1</td>\n",
       "      <td>I feel very sad for the people.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>A month after Hurricane Matthew, 800,000 Haiti...</td>\n",
       "      <td>model</td>\n",
       "      <td>I know, it's heartbreaking. The images of the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>A month after Hurricane Matthew, 800,000 Haiti...</td>\n",
       "      <td>individual_1</td>\n",
       "      <td>Yeah, the whole situation is horrible.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>A month after Hurricane Matthew, 800,000 Haiti...</td>\n",
       "      <td>model</td>\n",
       "      <td>It's absolutely tragic. The way the storm hit ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>A month after Hurricane Matthew, 800,000 Haiti...</td>\n",
       "      <td>individual_1</td>\n",
       "      <td>I know we can donate, but it's hard to know ex...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   conversation_id  turn_id  \\\n",
       "0                2        0   \n",
       "1                2        1   \n",
       "2                2        2   \n",
       "3                2        3   \n",
       "4                2        4   \n",
       "\n",
       "                                             article       speaker  \\\n",
       "0  A month after Hurricane Matthew, 800,000 Haiti...  individual_1   \n",
       "1  A month after Hurricane Matthew, 800,000 Haiti...         model   \n",
       "2  A month after Hurricane Matthew, 800,000 Haiti...  individual_1   \n",
       "3  A month after Hurricane Matthew, 800,000 Haiti...         model   \n",
       "4  A month after Hurricane Matthew, 800,000 Haiti...  individual_1   \n",
       "\n",
       "                                           utterance  \n",
       "0                    I feel very sad for the people.  \n",
       "1  I know, it's heartbreaking. The images of the ...  \n",
       "2             Yeah, the whole situation is horrible.  \n",
       "3  It's absolutely tragic. The way the storm hit ...  \n",
       "4  I know we can donate, but it's hard to know ex...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_long['turn_id'] = df_long.groupby('conversation_id').cumcount()\n",
    "\n",
    "df_long.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conversation_id</th>\n",
       "      <th>turn_id</th>\n",
       "      <th>article</th>\n",
       "      <th>speaker</th>\n",
       "      <th>utterance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>A month after Hurricane Matthew, 800,000 Haiti...</td>\n",
       "      <td>individual_1</td>\n",
       "      <td>I feel very sad for the people.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>A month after Hurricane Matthew, 800,000 Haiti...</td>\n",
       "      <td>model</td>\n",
       "      <td>I know, it's heartbreaking. The images of the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>A month after Hurricane Matthew, 800,000 Haiti...</td>\n",
       "      <td>individual_1</td>\n",
       "      <td>Yeah, the whole situation is horrible.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>A month after Hurricane Matthew, 800,000 Haiti...</td>\n",
       "      <td>model</td>\n",
       "      <td>It's absolutely tragic. The way the storm hit ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>A month after Hurricane Matthew, 800,000 Haiti...</td>\n",
       "      <td>individual_1</td>\n",
       "      <td>I know we can donate, but it's hard to know ex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8905</th>\n",
       "      <td>500</td>\n",
       "      <td>17</td>\n",
       "      <td>Death of former Putin aide at D.C. hotel is ru...</td>\n",
       "      <td>model</td>\n",
       "      <td>I understand why you'd think that, given the p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8906</th>\n",
       "      <td>500</td>\n",
       "      <td>18</td>\n",
       "      <td>Death of former Putin aide at D.C. hotel is ru...</td>\n",
       "      <td>individual_1</td>\n",
       "      <td>Or he could have slipped on something. Either ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8907</th>\n",
       "      <td>500</td>\n",
       "      <td>19</td>\n",
       "      <td>Death of former Putin aide at D.C. hotel is ru...</td>\n",
       "      <td>model</td>\n",
       "      <td>I know, it's a shame that his life ended in su...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8908</th>\n",
       "      <td>500</td>\n",
       "      <td>20</td>\n",
       "      <td>Death of former Putin aide at D.C. hotel is ru...</td>\n",
       "      <td>individual_1</td>\n",
       "      <td>ok thank you. bye!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8909</th>\n",
       "      <td>500</td>\n",
       "      <td>21</td>\n",
       "      <td>Death of former Putin aide at D.C. hotel is ru...</td>\n",
       "      <td>model</td>\n",
       "      <td>it was a good conversation. I'm glad we could ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8910 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      conversation_id  turn_id  \\\n",
       "0                   2        0   \n",
       "1                   2        1   \n",
       "2                   2        2   \n",
       "3                   2        3   \n",
       "4                   2        4   \n",
       "...               ...      ...   \n",
       "8905              500       17   \n",
       "8906              500       18   \n",
       "8907              500       19   \n",
       "8908              500       20   \n",
       "8909              500       21   \n",
       "\n",
       "                                                article       speaker  \\\n",
       "0     A month after Hurricane Matthew, 800,000 Haiti...  individual_1   \n",
       "1     A month after Hurricane Matthew, 800,000 Haiti...         model   \n",
       "2     A month after Hurricane Matthew, 800,000 Haiti...  individual_1   \n",
       "3     A month after Hurricane Matthew, 800,000 Haiti...         model   \n",
       "4     A month after Hurricane Matthew, 800,000 Haiti...  individual_1   \n",
       "...                                                 ...           ...   \n",
       "8905  Death of former Putin aide at D.C. hotel is ru...         model   \n",
       "8906  Death of former Putin aide at D.C. hotel is ru...  individual_1   \n",
       "8907  Death of former Putin aide at D.C. hotel is ru...         model   \n",
       "8908  Death of former Putin aide at D.C. hotel is ru...  individual_1   \n",
       "8909  Death of former Putin aide at D.C. hotel is ru...         model   \n",
       "\n",
       "                                              utterance  \n",
       "0                       I feel very sad for the people.  \n",
       "1     I know, it's heartbreaking. The images of the ...  \n",
       "2                Yeah, the whole situation is horrible.  \n",
       "3     It's absolutely tragic. The way the storm hit ...  \n",
       "4     I know we can donate, but it's hard to know ex...  \n",
       "...                                                 ...  \n",
       "8905  I understand why you'd think that, given the p...  \n",
       "8906  Or he could have slipped on something. Either ...  \n",
       "8907  I know, it's a shame that his life ended in su...  \n",
       "8908                                 ok thank you. bye!  \n",
       "8909  it was a good conversation. I'm glad we could ...  \n",
       "\n",
       "[8910 rows x 5 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "hh_df = pd.read_csv('/home/ajha/AP2/data/human-human-ocean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conversation_id</th>\n",
       "      <th>turn_id</th>\n",
       "      <th>text</th>\n",
       "      <th>Extroversion</th>\n",
       "      <th>Neuroticism</th>\n",
       "      <th>Agreeableness</th>\n",
       "      <th>Conscientiousness</th>\n",
       "      <th>Openness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>I feel very sad for the people.</td>\n",
       "      <td>-0.317092</td>\n",
       "      <td>0.186396</td>\n",
       "      <td>-0.138068</td>\n",
       "      <td>-0.609187</td>\n",
       "      <td>-0.174868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>It's terrible. Not only the people but the ani...</td>\n",
       "      <td>0.125101</td>\n",
       "      <td>0.284468</td>\n",
       "      <td>-0.213354</td>\n",
       "      <td>-0.817233</td>\n",
       "      <td>0.181743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Yeah, the whole situation is horrible.</td>\n",
       "      <td>-0.142737</td>\n",
       "      <td>0.286374</td>\n",
       "      <td>-0.277611</td>\n",
       "      <td>-0.814114</td>\n",
       "      <td>-0.079439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>I really wish there was something i could do.</td>\n",
       "      <td>-0.320769</td>\n",
       "      <td>0.238013</td>\n",
       "      <td>-0.138089</td>\n",
       "      <td>-0.382868</td>\n",
       "      <td>-0.183656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>I know we can donate, but it's hard to know ex...</td>\n",
       "      <td>-0.532262</td>\n",
       "      <td>0.060398</td>\n",
       "      <td>0.366289</td>\n",
       "      <td>0.625097</td>\n",
       "      <td>-0.191630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8771</th>\n",
       "      <td>500</td>\n",
       "      <td>16</td>\n",
       "      <td>Do you think maybe he was force to kill himself</td>\n",
       "      <td>-0.345693</td>\n",
       "      <td>0.122637</td>\n",
       "      <td>-0.187016</td>\n",
       "      <td>-0.777191</td>\n",
       "      <td>-0.108613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8772</th>\n",
       "      <td>500</td>\n",
       "      <td>17</td>\n",
       "      <td>I think somebody killed him</td>\n",
       "      <td>-0.394094</td>\n",
       "      <td>0.135951</td>\n",
       "      <td>-0.205856</td>\n",
       "      <td>-0.821231</td>\n",
       "      <td>-0.125072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8773</th>\n",
       "      <td>500</td>\n",
       "      <td>18</td>\n",
       "      <td>Or he could have slipped on something. Either ...</td>\n",
       "      <td>0.013900</td>\n",
       "      <td>0.252739</td>\n",
       "      <td>-0.116522</td>\n",
       "      <td>-0.589204</td>\n",
       "      <td>0.052598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8774</th>\n",
       "      <td>500</td>\n",
       "      <td>19</td>\n",
       "      <td>I don't know if he was nice or not. It was nic...</td>\n",
       "      <td>0.151929</td>\n",
       "      <td>0.284722</td>\n",
       "      <td>-0.258086</td>\n",
       "      <td>-0.807358</td>\n",
       "      <td>0.118684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8775</th>\n",
       "      <td>500</td>\n",
       "      <td>20</td>\n",
       "      <td>ok thank you. bye!</td>\n",
       "      <td>0.188732</td>\n",
       "      <td>0.279920</td>\n",
       "      <td>-0.293802</td>\n",
       "      <td>-0.831882</td>\n",
       "      <td>0.121357</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8776 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      conversation_id  turn_id  \\\n",
       "0                   2        0   \n",
       "1                   2        1   \n",
       "2                   2        2   \n",
       "3                   2        3   \n",
       "4                   2        4   \n",
       "...               ...      ...   \n",
       "8771              500       16   \n",
       "8772              500       17   \n",
       "8773              500       18   \n",
       "8774              500       19   \n",
       "8775              500       20   \n",
       "\n",
       "                                                   text  Extroversion  \\\n",
       "0                       I feel very sad for the people.     -0.317092   \n",
       "1     It's terrible. Not only the people but the ani...      0.125101   \n",
       "2                Yeah, the whole situation is horrible.     -0.142737   \n",
       "3         I really wish there was something i could do.     -0.320769   \n",
       "4     I know we can donate, but it's hard to know ex...     -0.532262   \n",
       "...                                                 ...           ...   \n",
       "8771    Do you think maybe he was force to kill himself     -0.345693   \n",
       "8772                        I think somebody killed him     -0.394094   \n",
       "8773  Or he could have slipped on something. Either ...      0.013900   \n",
       "8774  I don't know if he was nice or not. It was nic...      0.151929   \n",
       "8775                                 ok thank you. bye!      0.188732   \n",
       "\n",
       "      Neuroticism  Agreeableness  Conscientiousness  Openness  \n",
       "0        0.186396      -0.138068          -0.609187 -0.174868  \n",
       "1        0.284468      -0.213354          -0.817233  0.181743  \n",
       "2        0.286374      -0.277611          -0.814114 -0.079439  \n",
       "3        0.238013      -0.138089          -0.382868 -0.183656  \n",
       "4        0.060398       0.366289           0.625097 -0.191630  \n",
       "...           ...            ...                ...       ...  \n",
       "8771     0.122637      -0.187016          -0.777191 -0.108613  \n",
       "8772     0.135951      -0.205856          -0.821231 -0.125072  \n",
       "8773     0.252739      -0.116522          -0.589204  0.052598  \n",
       "8774     0.284722      -0.258086          -0.807358  0.118684  \n",
       "8775     0.279920      -0.293802          -0.831882  0.121357  \n",
       "\n",
       "[8776 rows x 8 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hh_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conversation_id</th>\n",
       "      <th>combined_turns</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0,1,2,3</td>\n",
       "      <td>I feel very sad for the people. I know, it's h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>4,5,6,7</td>\n",
       "      <td>I know we can donate, but it's hard to know ex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>8,9,10,11</td>\n",
       "      <td>Sorry to hear that, I'm glad that you are okay...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>12,13,14,15</td>\n",
       "      <td>Yeah, we never know what we can do unless we a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>16,17,18,19,20,21</td>\n",
       "      <td>The power of nature is truly scary. It's a sob...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   conversation_id     combined_turns  \\\n",
       "0                2            0,1,2,3   \n",
       "1                2            4,5,6,7   \n",
       "2                2          8,9,10,11   \n",
       "3                2        12,13,14,15   \n",
       "4                2  16,17,18,19,20,21   \n",
       "\n",
       "                                                text  \n",
       "0  I feel very sad for the people. I know, it's h...  \n",
       "1  I know we can donate, but it's hard to know ex...  \n",
       "2  Sorry to hear that, I'm glad that you are okay...  \n",
       "3  Yeah, we never know what we can do unless we a...  \n",
       "4  The power of nature is truly scary. It's a sob...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "def combine_turns(df, group_size=4):\n",
    "    combined_rows = []\n",
    "\n",
    "    for conversation_id, group in df.groupby('conversation_id'):\n",
    "        group = group.sort_values('turn_id').reset_index(drop=True)\n",
    "        num_turns = len(group)\n",
    "\n",
    "        i = 0\n",
    "        while i < num_turns:\n",
    "            # Check if remaining turns are less than group_size\n",
    "            if (num_turns - i) <= group_size and i != 0:\n",
    "                # Merge remaining turns with previous group\n",
    "                prev = combined_rows.pop()\n",
    "\n",
    "                combined_text = prev['text'] + \" \" + \" \".join(group.iloc[i:]['utterance'])\n",
    "                combined_turns = prev['combined_turns'] + \",\" + \",\".join(group.iloc[i:]['turn_id'].astype(str))\n",
    "                \n",
    "                combined_rows.append({\n",
    "                    'conversation_id': conversation_id,\n",
    "                    'combined_turns': combined_turns,\n",
    "                    'text': combined_text\n",
    "                })\n",
    "                break\n",
    "            else:\n",
    "                combined_text = \" \".join(group.iloc[i:i + group_size]['utterance'])\n",
    "                combined_turns = \",\".join(group.iloc[i:i + group_size]['turn_id'].astype(str))\n",
    "                \n",
    "                combined_rows.append({\n",
    "                    'conversation_id': conversation_id,\n",
    "                    'combined_turns': combined_turns,\n",
    "                    'text': combined_text\n",
    "                })\n",
    "                i += group_size\n",
    "\n",
    "    return pd.DataFrame(combined_rows)\n",
    "\n",
    "combined_expressive_hl_df = combine_turns(df_long)\n",
    "\n",
    "combined_expressive_hl_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_expressive_hl_df.to_csv('/home/ajha/AP2/data/combined_turns_expressive_hl_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conversation_id</th>\n",
       "      <th>combined_turns</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>0,1,2,3</td>\n",
       "      <td>what did you think about the article It was su...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>4,5,6,7</td>\n",
       "      <td>yeah some countries are so corrupt though true...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3</td>\n",
       "      <td>8,9,10,11</td>\n",
       "      <td>yeah wonder what was going through is head pro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3</td>\n",
       "      <td>12,13,14,15</td>\n",
       "      <td>makes sense. also find better ways rather than...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3</td>\n",
       "      <td>16,17,18,19</td>\n",
       "      <td>thats a great idea hopefully these people get ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3</td>\n",
       "      <td>20,21,22,23,24</td>\n",
       "      <td>were lucky to live here i agree makes my troub...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    conversation_id  combined_turns  \\\n",
       "5                 3         0,1,2,3   \n",
       "6                 3         4,5,6,7   \n",
       "7                 3       8,9,10,11   \n",
       "8                 3     12,13,14,15   \n",
       "9                 3     16,17,18,19   \n",
       "10                3  20,21,22,23,24   \n",
       "\n",
       "                                                 text  \n",
       "5   what did you think about the article It was su...  \n",
       "6   yeah some countries are so corrupt though true...  \n",
       "7   yeah wonder what was going through is head pro...  \n",
       "8   makes sense. also find better ways rather than...  \n",
       "9   thats a great idea hopefully these people get ...  \n",
       "10  were lucky to live here i agree makes my troub...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "combined_hh_df[combined_hh_df['conversation_id']==3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_hh_df.to_csv('/home/ajha/AP2/data/combined_turns_hh-df.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conversation_id</th>\n",
       "      <th>turn_id</th>\n",
       "      <th>speaker</th>\n",
       "      <th>utterance</th>\n",
       "      <th>article</th>\n",
       "      <th>Extroversion</th>\n",
       "      <th>Neuroticism</th>\n",
       "      <th>Agreeableness</th>\n",
       "      <th>Conscientiousness</th>\n",
       "      <th>Openness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>individual_1</td>\n",
       "      <td>I feel very sad for the people.</td>\n",
       "      <td>A month after Hurricane Matthew, 800,000 Haiti...</td>\n",
       "      <td>-0.317092</td>\n",
       "      <td>0.186396</td>\n",
       "      <td>-0.138068</td>\n",
       "      <td>-0.609187</td>\n",
       "      <td>-0.174868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>model</td>\n",
       "      <td>Me too, it's heartbreaking to see families str...</td>\n",
       "      <td>A month after Hurricane Matthew, 800,000 Haiti...</td>\n",
       "      <td>-0.036390</td>\n",
       "      <td>0.121401</td>\n",
       "      <td>0.225625</td>\n",
       "      <td>0.073282</td>\n",
       "      <td>0.148655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>individual_1</td>\n",
       "      <td>Yeah, the whole situation is horrible.</td>\n",
       "      <td>A month after Hurricane Matthew, 800,000 Haiti...</td>\n",
       "      <td>-0.142737</td>\n",
       "      <td>0.286374</td>\n",
       "      <td>-0.277611</td>\n",
       "      <td>-0.814114</td>\n",
       "      <td>-0.079439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>model</td>\n",
       "      <td>And the fact that there's a lack of coordinati...</td>\n",
       "      <td>A month after Hurricane Matthew, 800,000 Haiti...</td>\n",
       "      <td>-0.025742</td>\n",
       "      <td>0.030563</td>\n",
       "      <td>-0.047665</td>\n",
       "      <td>-0.430450</td>\n",
       "      <td>0.059493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>individual_1</td>\n",
       "      <td>I know we can donate, but it's hard to know ex...</td>\n",
       "      <td>A month after Hurricane Matthew, 800,000 Haiti...</td>\n",
       "      <td>-0.532262</td>\n",
       "      <td>0.060398</td>\n",
       "      <td>0.366289</td>\n",
       "      <td>0.625097</td>\n",
       "      <td>-0.191630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8905</th>\n",
       "      <td>500</td>\n",
       "      <td>33</td>\n",
       "      <td>model</td>\n",
       "      <td>It's possible, the article mentions that he wa...</td>\n",
       "      <td>Death of former Putin aide at D.C. hotel is ru...</td>\n",
       "      <td>-0.006357</td>\n",
       "      <td>0.034805</td>\n",
       "      <td>0.017900</td>\n",
       "      <td>-0.243165</td>\n",
       "      <td>0.068544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8906</th>\n",
       "      <td>500</td>\n",
       "      <td>36</td>\n",
       "      <td>individual_1</td>\n",
       "      <td>Or he could have slipped on something. Either ...</td>\n",
       "      <td>Death of former Putin aide at D.C. hotel is ru...</td>\n",
       "      <td>0.013900</td>\n",
       "      <td>0.252739</td>\n",
       "      <td>-0.116522</td>\n",
       "      <td>-0.589204</td>\n",
       "      <td>0.052598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8907</th>\n",
       "      <td>500</td>\n",
       "      <td>37</td>\n",
       "      <td>model</td>\n",
       "      <td>I know, it's sad. He was a pretty influential ...</td>\n",
       "      <td>Death of former Putin aide at D.C. hotel is ru...</td>\n",
       "      <td>-0.166833</td>\n",
       "      <td>0.092569</td>\n",
       "      <td>0.069657</td>\n",
       "      <td>-0.238407</td>\n",
       "      <td>0.055997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8908</th>\n",
       "      <td>500</td>\n",
       "      <td>40</td>\n",
       "      <td>individual_1</td>\n",
       "      <td>ok thank you. bye!</td>\n",
       "      <td>Death of former Putin aide at D.C. hotel is ru...</td>\n",
       "      <td>0.188732</td>\n",
       "      <td>0.279920</td>\n",
       "      <td>-0.293802</td>\n",
       "      <td>-0.831882</td>\n",
       "      <td>0.121357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8909</th>\n",
       "      <td>500</td>\n",
       "      <td>41</td>\n",
       "      <td>model</td>\n",
       "      <td>No problem, nice chatting with you.</td>\n",
       "      <td>Death of former Putin aide at D.C. hotel is ru...</td>\n",
       "      <td>-0.077528</td>\n",
       "      <td>0.201653</td>\n",
       "      <td>-0.252960</td>\n",
       "      <td>-0.797209</td>\n",
       "      <td>0.055345</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8910 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      conversation_id  turn_id       speaker  \\\n",
       "0                   2        0  individual_1   \n",
       "1                   2        1         model   \n",
       "2                   2        4  individual_1   \n",
       "3                   2        5         model   \n",
       "4                   2        8  individual_1   \n",
       "...               ...      ...           ...   \n",
       "8905              500       33         model   \n",
       "8906              500       36  individual_1   \n",
       "8907              500       37         model   \n",
       "8908              500       40  individual_1   \n",
       "8909              500       41         model   \n",
       "\n",
       "                                              utterance  \\\n",
       "0                       I feel very sad for the people.   \n",
       "1     Me too, it's heartbreaking to see families str...   \n",
       "2                Yeah, the whole situation is horrible.   \n",
       "3     And the fact that there's a lack of coordinati...   \n",
       "4     I know we can donate, but it's hard to know ex...   \n",
       "...                                                 ...   \n",
       "8905  It's possible, the article mentions that he wa...   \n",
       "8906  Or he could have slipped on something. Either ...   \n",
       "8907  I know, it's sad. He was a pretty influential ...   \n",
       "8908                                 ok thank you. bye!   \n",
       "8909                No problem, nice chatting with you.   \n",
       "\n",
       "                                                article  Extroversion  \\\n",
       "0     A month after Hurricane Matthew, 800,000 Haiti...     -0.317092   \n",
       "1     A month after Hurricane Matthew, 800,000 Haiti...     -0.036390   \n",
       "2     A month after Hurricane Matthew, 800,000 Haiti...     -0.142737   \n",
       "3     A month after Hurricane Matthew, 800,000 Haiti...     -0.025742   \n",
       "4     A month after Hurricane Matthew, 800,000 Haiti...     -0.532262   \n",
       "...                                                 ...           ...   \n",
       "8905  Death of former Putin aide at D.C. hotel is ru...     -0.006357   \n",
       "8906  Death of former Putin aide at D.C. hotel is ru...      0.013900   \n",
       "8907  Death of former Putin aide at D.C. hotel is ru...     -0.166833   \n",
       "8908  Death of former Putin aide at D.C. hotel is ru...      0.188732   \n",
       "8909  Death of former Putin aide at D.C. hotel is ru...     -0.077528   \n",
       "\n",
       "      Neuroticism  Agreeableness  Conscientiousness  Openness  \n",
       "0        0.186396      -0.138068          -0.609187 -0.174868  \n",
       "1        0.121401       0.225625           0.073282  0.148655  \n",
       "2        0.286374      -0.277611          -0.814114 -0.079439  \n",
       "3        0.030563      -0.047665          -0.430450  0.059493  \n",
       "4        0.060398       0.366289           0.625097 -0.191630  \n",
       "...           ...            ...                ...       ...  \n",
       "8905     0.034805       0.017900          -0.243165  0.068544  \n",
       "8906     0.252739      -0.116522          -0.589204  0.052598  \n",
       "8907     0.092569       0.069657          -0.238407  0.055997  \n",
       "8908     0.279920      -0.293802          -0.831882  0.121357  \n",
       "8909     0.201653      -0.252960          -0.797209  0.055345  \n",
       "\n",
       "[8910 rows x 10 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hl_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conversation_id</th>\n",
       "      <th>combined_turns</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0,1,4,5</td>\n",
       "      <td>I feel very sad for the people. Me too, it's h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>8,9,12,13</td>\n",
       "      <td>I know we can donate, but it's hard to know ex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>16,17,20,21</td>\n",
       "      <td>Sorry to hear that, I'm glad that you are okay...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>24,25,28,29</td>\n",
       "      <td>Yeah, we never know what we can do unless we a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>32,33,36,37,40,41</td>\n",
       "      <td>The power of nature is truly scary. I know, ri...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   conversation_id     combined_turns  \\\n",
       "0                2            0,1,4,5   \n",
       "1                2          8,9,12,13   \n",
       "2                2        16,17,20,21   \n",
       "3                2        24,25,28,29   \n",
       "4                2  32,33,36,37,40,41   \n",
       "\n",
       "                                                text  \n",
       "0  I feel very sad for the people. Me too, it's h...  \n",
       "1  I know we can donate, but it's hard to know ex...  \n",
       "2  Sorry to hear that, I'm glad that you are okay...  \n",
       "3  Yeah, we never know what we can do unless we a...  \n",
       "4  The power of nature is truly scary. I know, ri...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hl_df = pd.read_csv('/home/ajha/AP2/data/human-llm-ocean.csv')\n",
    "\n",
    "combined_hl_df = combine_turns(hl_df)\n",
    "combined_hl_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conversation_id</th>\n",
       "      <th>combined_turns</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>0,1,4,5</td>\n",
       "      <td>what did you think about the article I was sho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>8,9,12,13</td>\n",
       "      <td>yeah some countries are so corrupt though It's...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3</td>\n",
       "      <td>16,17,20,21</td>\n",
       "      <td>yeah wonder what was going through is head I k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3</td>\n",
       "      <td>24,25,28,29</td>\n",
       "      <td>makes sense. also find better ways rather than...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3</td>\n",
       "      <td>32,33,36,37</td>\n",
       "      <td>thats a great idea I think it would be a good ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3</td>\n",
       "      <td>40,41,44,45,48,49</td>\n",
       "      <td>were lucky to live here I know, we have so man...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    conversation_id     combined_turns  \\\n",
       "5                 3            0,1,4,5   \n",
       "6                 3          8,9,12,13   \n",
       "7                 3        16,17,20,21   \n",
       "8                 3        24,25,28,29   \n",
       "9                 3        32,33,36,37   \n",
       "10                3  40,41,44,45,48,49   \n",
       "\n",
       "                                                 text  \n",
       "5   what did you think about the article I was sho...  \n",
       "6   yeah some countries are so corrupt though It's...  \n",
       "7   yeah wonder what was going through is head I k...  \n",
       "8   makes sense. also find better ways rather than...  \n",
       "9   thats a great idea I think it would be a good ...  \n",
       "10  were lucky to live here I know, we have so man...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_hl_df[combined_hl_df['conversation_id']==3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_hl_df.to_csv('/home/ajha/AP2/data/combined_turns_hl-df.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## checking the average turn length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_ids = set(hh_df.conversation_id.values)\n",
    "turn_length = 0\n",
    "for conv_id in conv_ids:\n",
    "    turn_length += len(hh_df[hh_df['conversation_id']==3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "turn_length/len(conv_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding inferred dataset in the form of tables to DB for running trait inference using DLATK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1940"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import mysql.connector\n",
    "import pymysql\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Load CSVs\n",
    "# hh_df = pd.read_csv('/home/ajha/AP2/data/combined_turns_hh-df.csv')\n",
    "# hl_df = pd.read_csv('/home/ajha/AP2/data/combined_turns_hl-df.csv')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Step 1: Create the 'conversations_combined_turns' database\n",
    "conn = pymysql.connect(user='root', unix_socket='/home/ajha/mysql.sock', port=3307)\n",
    "cursor = conn.cursor()\n",
    "cursor.execute(\"CREATE DATABASE IF NOT EXISTS expressive_conversations;\")\n",
    "conn.commit()\n",
    "cursor.close()\n",
    "conn.close()\n",
    "\n",
    "# Step 2: Connect to 'conversations_combined_turns' DB\n",
    "engine = create_engine(\"mysql+pymysql://root@localhost:3307/expressive_conversations?unix_socket=/home/ajha/mysql.sock\")\n",
    "\n",
    "# Step 3: Insert DataFrames as tables\n",
    "combined_expressive_hl_df.to_sql(name='human_llm', con=engine, index=False, if_exists='replace')\n",
    "# hl_df.to_sql(name='human_llm', con=engine, index=False, if_exists='replace')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
